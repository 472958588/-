{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cc7c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.671567Z",
     "start_time": "2024-06-10T10:13:21.527604Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#导包\n",
    "from netCDF4 import Dataset\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import ConvLSTM2D,LSTM, BatchNormalization, LayerNormalization,Input, Conv3D, TimeDistributed, Flatten\n",
    "from tensorflow.keras.layers import Concatenate,Conv2D,TimeDistributed, MaxPooling2D, Input, MaxPooling3D\n",
    "from tensorflow.keras.layers import  Reshape,multiply\n",
    "from tensorflow.keras.layers import Layer,Lambda,Dot,ReLU, Dense, Dropout, Activation, Flatten,Attention\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.metrics import r2_score,accuracy_score,precision_score\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, Sequential, regularizers\n",
    "# calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import gc \n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import match\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619adb84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.817334Z",
     "start_time": "2024-06-10T10:13:24.673564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查可用GPU数量\n",
    "len(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580b19d",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a969a48c",
   "metadata": {},
   "source": [
    "## SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2879bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.826320Z",
     "start_time": "2024-06-10T10:13:24.818332Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ssh = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/SSH/SSH_2005-2015_month.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d073208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.834306Z",
     "start_time": "2024-06-10T10:13:24.828316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "time_ssh = data_ssh['time'][:]\n",
    "print(len(time_ssh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601b1b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.839298Z",
     "start_time": "2024-06-10T10:13:24.835305Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 查看研究区域经纬度\n",
    "ssh_lat = data_ssh['lat'][:].data\n",
    "#print(ssh_lat[:])\n",
    "ssh_lon = data_ssh['lon'][:].data\n",
    "#print(ssh_lon[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e7d608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:24.987062Z",
     "start_time": "2024-06-10T10:13:24.840297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "ssh = data_ssh['ssh'][:].data\n",
    "print(ssh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c26b86a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.102876Z",
     "start_time": "2024-06-10T10:13:24.988060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.20051, -0.43673334)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax(ssh),np.nanmin(ssh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203facec",
   "metadata": {},
   "source": [
    "## SSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fde41f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.107868Z",
     "start_time": "2024-06-10T10:13:25.103874Z"
    }
   },
   "outputs": [],
   "source": [
    "data_sss = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/SSS/dataset-sss-ssd-rep-monthly_2005-2020.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c14ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.112860Z",
     "start_time": "2024-06-10T10:13:25.108867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "# 确定时间\n",
    "time_sss = data_sss['time'][:132]\n",
    "print(len(time_sss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463ec7e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.117871Z",
     "start_time": "2024-06-10T10:13:25.114856Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取研究位置经纬度\n",
    "sss_lat = data_sss['lat'][:].data\n",
    "#print(sss_lat[:])\n",
    "sss_lon = data_sss['lon'][:].data\n",
    "#print(sss_lon[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778ef529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.339496Z",
     "start_time": "2024-06-10T10:13:25.118850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 1, 280, 600)\n",
      "(132, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "sss = data_sss['sos'][:132].data \n",
    "print(sss.shape)\n",
    "sss = np.squeeze(sss) # 移除大小为一的维度\n",
    "print(sss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e08930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.416373Z",
     "start_time": "2024-06-10T10:13:25.340495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.072178, 13.604756)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax(sss),np.nanmin(sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5c8e2",
   "metadata": {},
   "source": [
    "## SSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d026b883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.423362Z",
     "start_time": "2024-06-10T10:13:25.417372Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ssw = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/SSW/anon_ssw_2005_2018_Month_data.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09f6f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.428354Z",
     "start_time": "2024-06-10T10:13:25.424361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "# 确定时间\n",
    "time_ssw = data_ssw['time'][:132]\n",
    "print(len(time_ssw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447b145c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.433346Z",
     "start_time": "2024-06-10T10:13:25.429353Z"
    }
   },
   "outputs": [],
   "source": [
    "lat_ssw = data_ssw['lat'][:].data\n",
    "#print(lat_ssw[314:594])\n",
    "lon_ssw = data_ssw['lon'][:].data\n",
    "#print(lon_ssw[440:1040])\n",
    "\n",
    "# lat 0.125    ----    69.875\n",
    "# lon  110.125    ----    259.875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68eef6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.731868Z",
     "start_time": "2024-06-10T10:13:25.434345Z"
    }
   },
   "outputs": [],
   "source": [
    "uwnd = data_ssw['uwnd'][:132,314:594,440:1040].data  \n",
    "vwnd = data_ssw['vwnd'][:132,314:594,440:1040].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83cf7d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.736861Z",
     "start_time": "2024-06-10T10:13:25.732867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600)\n",
      "(132, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "print(uwnd.shape)\n",
    "print(vwnd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c8a2cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.797763Z",
     "start_time": "2024-06-10T10:13:25.737859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.433594, -11.7988205, 8.8359995, -13.645481)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax(uwnd),np.nanmin(uwnd),np.nanmax(vwnd),np.nanmin(vwnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334792f",
   "metadata": {},
   "source": [
    "## 3DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02ac03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:25.803753Z",
     "start_time": "2024-06-10T10:13:25.798761Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_3dt_1 = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/3DT/dataset-armor-3d-rep-monthly_2005-2009.nc')\n",
    "# data_3dt_2 = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/3DT/dataset-armor-3d-rep-monthly_2010-2015.nc')\n",
    "\n",
    "data_3ds = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/3DT/sali/3DS_end_2005_2015.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c15b88bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:28.987652Z",
     "start_time": "2024-06-10T10:13:25.804752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 43, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "sali_depth = data_3ds['so'][:].data\n",
    "print(sali_depth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d9df5",
   "metadata": {},
   "source": [
    "###  5 - 2000m 温度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98f2e6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:28.993643Z",
     "start_time": "2024-06-10T10:13:28.988650Z"
    }
   },
   "outputs": [],
   "source": [
    "# 所有深度层\n",
    "depths = [0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,80,90,100,125,150,175,200,225,250,275,300,350,400,\n",
    "         450,500,550,600,700,800,900,1000,1100,1200,1300,1400,1500,1750,2000]\n",
    "\n",
    "#选取的深度层\n",
    "depths_use = [10,15,20,30,40,50,60,70,80,90,100,125,150,175,200,225,250,275,300,350,400,\n",
    "              500,600,700,800,900,1000,1100,1300,1500,1750,2000]\n",
    "\n",
    "#[50,100,125,150,200,250,300,400,500,600,700,800,900,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340dd8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:28.997636Z",
     "start_time": "2024-06-10T10:13:28.994641Z"
    }
   },
   "outputs": [],
   "source": [
    "sali_depth_use = sali_depth[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a693fa1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:56.191056Z",
     "start_time": "2024-06-10T10:13:28.998634Z"
    }
   },
   "outputs": [],
   "source": [
    "for i,depth in enumerate(depths):\n",
    "    if(depth in depths_use):\n",
    "        #print(depths[i])\n",
    "        sali_depth_use = np.concatenate((sali_depth_use,sali_depth[:,i:i+1]),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a271c345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:56.197047Z",
     "start_time": "2024-06-10T10:13:56.192055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 33, 280, 600)\n",
      "(132, 280, 600, 33)\n"
     ]
    }
   ],
   "source": [
    "print(sali_depth_use.shape)\n",
    "sali_depth_use = np.transpose(sali_depth_use, (0,2,3,1))\n",
    "print(sali_depth_use.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9055f",
   "metadata": {},
   "source": [
    "## SST表面温度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9700303f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:13:56.203037Z",
     "start_time": "2024-06-10T10:13:56.198045Z"
    }
   },
   "outputs": [],
   "source": [
    "data_3dt_1 = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/3DT/dataset-armor-3d-rep-monthly_2005-2009.nc')\n",
    "data_3dt_2 = nc.Dataset(r'D:/codeFile/jupyterDemo/3d_ts/BPNN/data/3DT/dataset-armor-3d-rep-monthly_2010-2015.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67388590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:10.178635Z",
     "start_time": "2024-06-10T10:13:56.204036Z"
    }
   },
   "outputs": [],
   "source": [
    "sst_1 = data_3dt_1['to'][:].data\n",
    "sst_2 = data_3dt_2['to'][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f28faae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:10.184626Z",
     "start_time": "2024-06-10T10:14:10.179634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 43, 280, 600)\n",
      "(72, 43, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "print(sst_1.shape)\n",
    "print(sst_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da2170d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:13.927625Z",
     "start_time": "2024-06-10T10:14:10.189618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 43, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "temp_depth = np.append(sst_1,sst_2,axis=0)\n",
    "print(temp_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6234b015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:13.932617Z",
     "start_time": "2024-06-10T10:14:13.928624Z"
    }
   },
   "outputs": [],
   "source": [
    "sst = temp_depth[:,0:1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f16fbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:13.937609Z",
     "start_time": "2024-06-10T10:14:13.933616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600)\n"
     ]
    }
   ],
   "source": [
    "sst = np.squeeze(sst)\n",
    "print(sst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe4126",
   "metadata": {},
   "source": [
    "## 数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca14a35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:14.806217Z",
     "start_time": "2024-06-10T10:14:13.938608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600) (132, 280, 600) (132, 280, 600) (132, 280, 600) (132, 280, 600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(132, 280, 600, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在通道维度对数据进行合并\n",
    "print(ssh.shape,sst.shape,uwnd.shape,vwnd.shape,sss.shape)\n",
    "cat_data =np.stack((ssh,sst,uwnd,vwnd,sss),axis=3)\n",
    "cat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31946f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:18.225735Z",
     "start_time": "2024-06-10T10:14:14.807215Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将表面数据和水下数据在最后一个维度拼接，将空值删除。\n",
    "cat_data_ss_depth = np.concatenate((cat_data,sali_depth_use),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f4b2121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:18.231725Z",
     "start_time": "2024-06-10T10:14:18.226733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 280, 600, 38)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data_ss_depth.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539202b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-08T07:54:27.397519Z",
     "start_time": "2023-10-08T07:54:27.393526Z"
    }
   },
   "source": [
    "## 将两个温度异常区域的数据设置为nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a958aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:18.235719Z",
     "start_time": "2024-06-10T10:14:18.232725Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = temp_depth_use[:,:,:,27:28]\n",
    "# test[test < 0.4] = np.nan\n",
    "# test[test > 10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6155394a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:18.239712Z",
     "start_time": "2024-06-10T10:14:18.236717Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_data_ss_depth[:,:,:,32:33] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10f15c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:18.243706Z",
     "start_time": "2024-06-10T10:14:18.240711Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_data_ss_depth.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2596fa1",
   "metadata": {},
   "source": [
    "## 将填充值赋值为NAN，且一个点中有一个维度为nan，则将这个点的所有维度都设置为nan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "119f831a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:37.198301Z",
     "start_time": "2024-06-10T10:14:34.718278Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 600, 132, 38)\n",
      "(168000, 5016)\n"
     ]
    }
   ],
   "source": [
    "## 先对合并的数据进行reshape成（长*宽，时间*通道），此步骤是为了统一图像， 让所有时间所有深度的图像都相同。\n",
    "cat_data_ss_depth_reshape  = np.transpose(cat_data_ss_depth,(1,2,0,3))\n",
    "print(cat_data_ss_depth_reshape.shape)\n",
    "cat_data_ss_depth_reshape = cat_data_ss_depth_reshape.reshape ((-1,132*38))\n",
    "print(cat_data_ss_depth_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb75b4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:39.126210Z",
     "start_time": "2024-06-10T10:14:37.199300Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 将填充值赋值为nan\n",
    "cat_data_ss_depth_reshape[cat_data_ss_depth_reshape == 32767] = np.nan\n",
    "nan_mask = np.isnan(cat_data_ss_depth_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53dc0aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:40.556421Z",
     "start_time": "2024-06-10T10:14:40.499512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63271"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看nan的个数 63271\n",
    "np.sum(nan_mask.any(axis=1) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d1f0613",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:48.669997Z",
     "start_time": "2024-06-10T10:14:48.431379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_data_ss_depth_reshape: (168000, 5016)\n"
     ]
    }
   ],
   "source": [
    "# 通过布尔索引删除NaN值。\n",
    "cat_data_ss_depth_reshape[nan_mask.any(axis=1) == True] = np.nan   \n",
    "# nan_mask.any(axis=1)==true,只要第一个维度中含有nan就将所有设置为nan。\n",
    "print('cat_data_ss_depth_reshape:',cat_data_ss_depth_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d989b8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:53.583829Z",
     "start_time": "2024-06-10T10:14:53.575842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63271"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看nan的个数，共有63271\n",
    "np.sum(np.isnan(cat_data_ss_depth_reshape[:,5])) # 此处写几都可以，得到的nan的数量都是相同的。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e15bafbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:56.580785Z",
     "start_time": "2024-06-10T10:14:56.575793Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168000, 132, 38)\n",
      "(132, 168000, 38)\n"
     ]
    }
   ],
   "source": [
    "cat_data_ss_depth_reshape = cat_data_ss_depth_reshape.reshape(-1,132,38)\n",
    "print(cat_data_ss_depth_reshape.shape)\n",
    "cat_data_ss_depth_reshape = np.transpose(cat_data_ss_depth_reshape,(1,0,2))\n",
    "print(cat_data_ss_depth_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ab62a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:56.907262Z",
     "start_time": "2024-06-10T10:14:56.903268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600, 38)\n"
     ]
    }
   ],
   "source": [
    "cat_data_ss_depth_reshape = cat_data_ss_depth_reshape.reshape(-1,280,600,38)\n",
    "print(cat_data_ss_depth_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b2b2040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:58.840161Z",
     "start_time": "2024-06-10T10:14:58.832174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63271"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 确认nan的个数 63271\n",
    "np.sum(np.isnan(cat_data_ss_depth_reshape[1:2,:,:,2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab13d602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:59.029857Z",
     "start_time": "2024-06-10T10:14:59.024865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168000, 5016)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31da4f",
   "metadata": {},
   "source": [
    "## 将数据分成小块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2962990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:59.839559Z",
     "start_time": "2024-06-10T10:14:59.834567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 280, 600, 5) (132, 280, 600, 33)\n"
     ]
    }
   ],
   "source": [
    "cat_data_ss = cat_data_ss_depth_reshape[:,:,:,:5]    #表面数据\n",
    "cat_data_depth = cat_data_ss_depth_reshape[:,:,:,5:]  #次表层数据\n",
    "print(cat_data_ss.shape,cat_data_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a29a94cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:33.013064Z",
     "start_time": "2024-06-10T10:15:00.239917Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_size: 132 lat_size: 280 lon_size: 600\n",
      "272 592\n",
      "out_data的形状 (132, 272, 592, 9, 9, 5)\n",
      "out_data_y的形状 (132, 272, 592, 33)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "time_size, lat_size, lon_size, channel = cat_data_ss.shape   # （132，280，600，5）\n",
    "\n",
    "# 定义矩形框的大小和步幅           \n",
    "box_size = 9  # 单位为度\n",
    "step_size = 1  # 滑动步幅\n",
    "\n",
    "# 计算输出网格的形状\n",
    "out_lat_size = (lat_size - box_size) // step_size  + 1 \n",
    "out_lon_size = (lon_size - box_size) // step_size  + 1 \n",
    "\n",
    "print('time_size:',time_size,'lat_size:',lat_size,'lon_size:',lon_size)   #(132 280 600)\n",
    "print(out_lat_size,out_lon_size)  #(272 592)\n",
    "\n",
    "#输出数组 \n",
    "out_data = np.zeros((time_size, out_lat_size , out_lon_size, box_size, box_size, channel)) #(132, 272, 592, 9,9,5)\n",
    "out_data_y = np.zeros((time_size, out_lat_size , out_lon_size, 33)) #(132, 272, 592,15)\n",
    "\n",
    "# 遍历时间步、纬度和经度\n",
    "for t in range(time_size):\n",
    "    sample_idx = 0\n",
    "    for lat in range(0, lat_size - box_size +1, step_size):\n",
    "        for lon in range(0, lon_size - box_size +1, step_size):\n",
    "            # 计算当前矩形框的边界\n",
    "            lat_min = lat\n",
    "            lat_max = lat + box_size\n",
    "            lon_min = lon\n",
    "            lon_max = lon + box_size\n",
    "            #print(lat_min,lat_max,lon_min,lon_max)\n",
    "            # 获取当前矩形框的地图数据\n",
    "            box_data = cat_data_ss[t, lat_min:lat_max, lon_min:lon_max,:]\n",
    "            # 写入数组中\n",
    "#             lat_ = lat//4\n",
    "#             lon_ = lon//4\n",
    "            out_data[t,lat,lon, :, :, :] = box_data\n",
    "            box_data = []\n",
    "            #print(sample_idx)\n",
    "            # 增加样本计数器\n",
    "            sample_idx += 1\n",
    "\n",
    "print('out_data的形状',out_data.shape)\n",
    "#return out_data\n",
    "    \n",
    "#==============================================================================#   \n",
    "\n",
    "# 遍历时间步、纬度和经度\n",
    "for t in range(time_size):\n",
    "    sample_idx = 0\n",
    "    for lat in range(4, lat_size-4, step_size):\n",
    "        for lon in range(4, lon_size-4, step_size):\n",
    "            box_data_y = cat_data_depth[t, lat:lat+1, lon:lon+1,:]\n",
    "            out_data_y[t,lat-4,lon-4, :] = box_data_y\n",
    "            box_data_y = []\n",
    "            #print(sample_idx)\n",
    "            # 增加样本计数器\n",
    "            sample_idx += 1\n",
    "\n",
    "print('out_data_y的形状',out_data_y.shape)\n",
    "    \n",
    "# out_data_reshape = slider_value(cat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711d229",
   "metadata": {},
   "source": [
    "### test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aafb18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:33.018056Z",
     "start_time": "2024-06-10T10:16:33.014063Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.sum(np.isnan(out_data_y[1:2,:,:,2:3]))  # 之前的nan值个数为61950，当前为57599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4204fcc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:33.023048Z",
     "start_time": "2024-06-10T10:16:33.019055Z"
    }
   },
   "outputs": [],
   "source": [
    "#out_data[1,24,1,:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a999e182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:33.028041Z",
     "start_time": "2024-06-10T10:16:33.024047Z"
    }
   },
   "outputs": [],
   "source": [
    "#out_data_y[1,24,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7b58e",
   "metadata": {},
   "source": [
    "## 删除缺失值多于一半的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ea49d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T13:31:17.158866Z",
     "start_time": "2023-10-14T13:31:17.155871Z"
    }
   },
   "source": [
    "### 获取NAN_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15a0ff6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:33.033032Z",
     "start_time": "2024-06-10T10:16:33.029039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 272, 592, 9, 9, 5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c7ead8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:40.822530Z",
     "start_time": "2024-06-10T10:16:33.034032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 161024, 9, 9, 5)\n",
      "(132, 161024, 9, 9, 5)\n"
     ]
    }
   ],
   "source": [
    "# 修改变量形状    \n",
    "out_data_reshape = out_data.reshape((132,-1,9,9,5))\n",
    "print(out_data_reshape.shape) \n",
    "\n",
    "# 获取变量nan掩码\n",
    "nan_mask_out_data = np.isnan(out_data_reshape)\n",
    "print(nan_mask_out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdccd35b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:40.837506Z",
     "start_time": "2024-06-10T10:16:40.823528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4764087"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# （161024，9，9）中存在4666932个nan\n",
    "np.count_nonzero(nan_mask_out_data[7:8,:,:,:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d8748f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:40.842498Z",
     "start_time": "2024-06-10T10:16:40.838504Z"
    }
   },
   "outputs": [],
   "source": [
    "# 选取一个作为代表(都一样)\n",
    "nan_mask_out_data_one = nan_mask_out_data[0,:,:,:,0]   #(161024, 9, 9)\n",
    "nan_mask_out_data_one = nan_mask_out_data_one.reshape(-1,9*9) #（161024，81）    # 其中true 代表Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754c66a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.611513Z",
     "start_time": "2024-06-10T10:14:19.611513Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看mask中Nan 的个数\n",
    "#np.count_nonzero(nan_mask_out_data_one)     # 4666932\n",
    "#查看形状\n",
    "#nan_mask_out_data_one.shape     # 161024, 81)\n",
    "# 查看内容\n",
    "#nan_mask_out_data_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcb4cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:57:58.880771Z",
     "start_time": "2024-06-10T09:57:58.875779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196a96c6",
   "metadata": {},
   "source": [
    "### 为有效值大于一半的方块标注True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bfa7b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:46.141340Z",
     "start_time": "2024-06-10T10:16:45.993578Z"
    }
   },
   "outputs": [],
   "source": [
    "nan_mask_cnn = [] \n",
    "for i in nan_mask_out_data_one:\n",
    "    if(np.count_nonzero(i) <=40):    #True 代表nan，当nan小于等于40时，代表有效值大于一半\n",
    "        nan_mask_cnn.append(True)\n",
    "    else:\n",
    "        nan_mask_cnn.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ac9b281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:47.970811Z",
     "start_time": "2024-06-10T10:16:47.961825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161024,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask_cnn = np.array(nan_mask_cnn)\n",
    "nan_mask_cnn.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "180eac23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:16:48.186465Z",
     "start_time": "2024-06-10T10:16:48.181474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102607"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(nan_mask_cnn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43799205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:08:18.596454Z",
     "start_time": "2024-06-10T09:08:18.592461Z"
    }
   },
   "source": [
    "### 去除中心点为Nan的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0e94191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:17:06.036332Z",
     "start_time": "2024-06-10T10:17:06.031340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 161024, 9, 9, 5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask_out_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "502d52e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:17:11.114311Z",
     "start_time": "2024-06-10T10:17:11.110317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161024,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask_out_data[0,:,4,4,0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfe91c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:17:40.091936Z",
     "start_time": "2024-06-10T10:17:39.939182Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(nan_mask_out_data[0,:,4,4,0]):\n",
    "    if(i==True):  # True代表nan\n",
    "        nan_mask_cnn[index] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf154bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:17:40.337551Z",
     "start_time": "2024-06-10T10:17:40.334547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101799"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(nan_mask_cnn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "899afd0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:17:42.252468Z",
     "start_time": "2024-06-10T10:17:42.247475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_data_reshape: (161024, 132, 9, 9, 5)\n",
      "out_data_y_reshape: (272, 592, 132, 33)\n",
      "out_data_y_reshape: (161024, 132, 33)\n"
     ]
    }
   ],
   "source": [
    "out_data_reshape =  np.transpose(out_data_reshape,(1,0,2,3,4))\n",
    "print('out_data_reshape:',out_data_reshape.shape)\n",
    "out_data_y_reshape =  np.transpose(out_data_y,(1,2,0,3))\n",
    "print('out_data_y_reshape:',out_data_y_reshape.shape)\n",
    "out_data_y_reshape = out_data_y_reshape.reshape(-1,132,33)\n",
    "print('out_data_y_reshape:',out_data_y_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14075089",
   "metadata": {},
   "source": [
    "## 开始删除无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93ad4743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:18:02.608781Z",
     "start_time": "2024-06-10T10:17:44.218311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101799, 132, 9, 9, 5) (101799, 132, 33)\n"
     ]
    }
   ],
   "source": [
    "out_data_reshape = out_data_reshape[nan_mask_cnn]\n",
    "out_data_y_reshape = out_data_y_reshape[nan_mask_cnn]\n",
    "print(out_data_reshape.shape,out_data_y_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddb083",
   "metadata": {},
   "source": [
    "## 使用0来填充nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d3199a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:19:11.711980Z",
     "start_time": "2024-06-10T10:18:08.446586Z"
    }
   },
   "outputs": [],
   "source": [
    "out_data_reshape = np.nan_to_num(out_data_reshape, nan=0)   # (103623, 132, 9, 9, 5) \n",
    "out_data_y_reshape = np.nan_to_num(out_data_y_reshape, nan=0)  #(103623, 132, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6b9cb",
   "metadata": {},
   "source": [
    "# 验证集和测试集的划分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e542bf9",
   "metadata": {},
   "source": [
    "## 对数据进行reshape,以进行数据集的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91064314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:19:11.717971Z",
     "start_time": "2024-06-10T10:19:11.712979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_data_reshape: (132, 101799, 9, 9, 5)\n",
      "out_data_y_reshape: (132, 101799, 33)\n"
     ]
    }
   ],
   "source": [
    "out_data_reshape = np.transpose(out_data_reshape,(1,0,2,3,4))\n",
    "print('out_data_reshape:',out_data_reshape.shape)\n",
    "out_data_y_reshape =  np.transpose(out_data_y_reshape,(1,0,2))\n",
    "print('out_data_y_reshape:',out_data_y_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce22e0d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:20:28.529696Z",
     "start_time": "2024-06-10T10:20:28.525702Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最后十二个月的数据作为test\n",
    "test_num = 120\n",
    "x_train = out_data_reshape[:test_num]\n",
    "y_train = out_data_y_reshape[:test_num]\n",
    "\n",
    "x_test = out_data_reshape[test_num:]\n",
    "y_test = out_data_y_reshape[test_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08307c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:20:30.686690Z",
     "start_time": "2024-06-10T10:20:30.681698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 101799, 9, 9, 5),\n",
       " (120, 101799, 33),\n",
       " (12, 101799, 9, 9, 5),\n",
       " (12, 101799, 33))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看形状\n",
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e9bf3c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:21:11.415669Z",
     "start_time": "2024-06-10T10:20:51.747270Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将前两个维度进行合并  时间*(lat*lon)\n",
    "x_train = np.reshape(x_train,(-1,9,9,5))\n",
    "x_test = np.reshape(x_test,(-1,9,9,5))\n",
    "\n",
    "y_train = np.reshape(y_train,(-1,33))\n",
    "y_test = np.reshape(y_test,(-1,33))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82145a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T11:16:55.407824Z",
     "start_time": "2023-09-27T11:16:55.403831Z"
    }
   },
   "source": [
    "## 划分训练数据和目标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef288642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:21:11.421659Z",
     "start_time": "2024-06-10T10:21:11.417666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test.shape: (1221588, 9, 9, 5)\n",
      "y_test.shape (1221588, 33)\n",
      "x_train (12215880, 9, 9, 5)\n",
      "y_train (12215880, 33)\n"
     ]
    }
   ],
   "source": [
    "print('x_test.shape:',x_test.shape)\n",
    "print('y_test.shape',y_test.shape)\n",
    "print('x_train',x_train.shape)\n",
    "print('y_train',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57afe328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:21:34.909919Z",
     "start_time": "2024-06-10T10:21:11.422658Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这是验证集和训练集的划分是随机选取。\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56fdc0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:21:34.915909Z",
     "start_time": "2024-06-10T10:21:34.911916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (8551116, 9, 9, 5)\n",
      "x_test (1221588, 9, 9, 5)\n",
      "x_val (3664764, 9, 9, 5)\n",
      "y_train (8551116, 33)\n",
      "y_test (1221588, 33)\n",
      "y_val (3664764, 33)\n"
     ]
    }
   ],
   "source": [
    "print('x_train',x_train.shape)\n",
    "print('x_test',x_test.shape)\n",
    "print('x_val',x_val.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('y_val',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfdb57",
   "metadata": {},
   "source": [
    "# 特征归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e7a1057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:21:37.810268Z",
     "start_time": "2024-06-10T10:21:37.806275Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 记录数据集的形状\n",
    "x_train_shape = x_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "\n",
    "x_test_shape = x_test.shape\n",
    "y_test_shape = y_test.shape\n",
    "\n",
    "x_val_shape = x_val.shape\n",
    "y_val_shape = y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e19fa83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:41.542195Z",
     "start_time": "2024-06-10T10:21:54.594058Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler_f = StandardScaler()\n",
    "x_train = scaler_f.fit_transform(x_train.reshape(-1,x_train_shape[3])) \n",
    "x_test = scaler_f.transform(x_test.reshape(-1,x_test_shape[3]))\n",
    "x_val = scaler_f.transform(x_val.reshape(-1,x_val_shape[3]))\n",
    "\n",
    "scaler_l = StandardScaler()\n",
    "y_train = scaler_l.fit_transform(y_train.reshape(-1,y_train_shape[1])) \n",
    "y_test = scaler_l.transform(y_test.reshape(-1,y_test_shape[1])) \n",
    "y_val = scaler_l.transform(y_val.reshape(-1,y_val_shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5efe52e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:41.548186Z",
     "start_time": "2024-06-10T10:23:41.543194Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(-1,9,9,5))\n",
    "x_test = np.reshape(x_test,(-1,9,9,5))\n",
    "x_val = np.reshape(x_val,(-1,9,9,5))\n",
    "y_train = np.reshape(y_train,(-1,33))\n",
    "y_test = np.reshape(y_test,(-1,33))\n",
    "y_val = np.reshape(y_val,(-1,33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5cd9d9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:41.554176Z",
     "start_time": "2024-06-10T10:23:41.549184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (8551116, 9, 9, 5)\n",
      "x_test (1221588, 9, 9, 5)\n",
      "x_val (3664764, 9, 9, 5)\n",
      "y_train (8551116, 33)\n",
      "y_test (1221588, 33)\n",
      "y_val (3664764, 33)\n"
     ]
    }
   ],
   "source": [
    "print('x_train',x_train.shape)\n",
    "print('x_test',x_test.shape)\n",
    "print('x_val',x_val.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('y_val',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82214b18",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be193a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:46.968736Z",
     "start_time": "2024-06-10T10:23:46.964743Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # 创建神经网络模型\n",
    "# def create_model():   \n",
    "#     model = models.Sequential([\n",
    "#         layers.Dense(200, activation='tanh', input_shape=(5,)),  # 输入层和隐藏层\n",
    "#         layers.Dense(15, activation='tanh'),\n",
    "#         layers.Dense(8, activation='tanh'),\n",
    "#         layers.Dense(1, activation='linear')  # 输出层，num_depths表示深度的数量\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model \n",
    "# #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bde37741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:49.703464Z",
     "start_time": "2024-06-10T10:23:49.697474Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ChannelAttention(inputs,in_planes, ratio=2):\n",
    "    \n",
    "    avg_out= layers.GlobalAveragePooling2D()\n",
    "    max_out= layers.GlobalMaxPooling2D()\n",
    "\n",
    "    fc1 = layers.Dense(in_planes//ratio, kernel_initializer='he_normal',\n",
    "                            kernel_regularizer=regularizers.l2(5e-4),\n",
    "                            activation=tf.nn.relu,\n",
    "                            use_bias=True, bias_initializer='zeros')\n",
    "    fc2 = layers.Dense(in_planes, kernel_initializer='he_normal',\n",
    "                            kernel_regularizer=regularizers.l2(5e-4),\n",
    "                            use_bias=True, bias_initializer='zeros')\n",
    "\n",
    "    \n",
    "    avg_out = avg_out(inputs)\n",
    "    max_out = max_out(inputs)\n",
    "    out = tf.stack([avg_out, max_out], axis=1)  # shape=(None, 2, fea_num)\n",
    "    out = fc2(fc1(out))\n",
    "    out = tf.reduce_sum(out, axis=1)             # shape=(256, 512)\n",
    "    out = tf.nn.sigmoid(out)\n",
    "    out = layers.Reshape((1, 1, out.shape[1]))(out)\n",
    "\n",
    "    return  out*inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9947b9bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:50.563265Z",
     "start_time": "2024-06-10T10:23:50.557275Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def regularized_padded_conv(*args, **kwargs):\n",
    "    return layers.Conv2D(*args, **kwargs, padding='same', use_bias=False,\n",
    "                         kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=regularizers.l2(5e-4))\n",
    "\n",
    "def SpatialAttention(inputs,kernel_size=5):\n",
    "    conv1 = regularized_padded_conv(1, kernel_size=kernel_size, strides=1, activation='sigmoid')\n",
    "    avg_out = tf.reduce_mean(inputs, axis=3)\n",
    "    max_out = tf.reduce_max(inputs, axis=3)\n",
    "    out = tf.stack([avg_out, max_out], axis=-1)             # 创建一个维度,拼接到一起concat。\n",
    "    out = conv1(out)\n",
    "    return out*inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "174d3a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:52.305948Z",
     "start_time": "2024-06-10T10:23:52.301954Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cbam_block(inputs, in_planes,ratio=2):\n",
    "\n",
    "    cbam_feature = ChannelAttention(inputs, in_planes,ratio)\n",
    "    cbam_feature = SpatialAttention(cbam_feature)\n",
    "    return cbam_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09016b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:53.947380Z",
     "start_time": "2024-06-10T10:23:53.942367Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model_input= Input(shape=x_train.shape[1:])\n",
    "    output_size = 1\n",
    "    x = cbam_block(model_input,5)\n",
    "    x = Conv2D(filters=16, kernel_size=(3, 3),strides=1)(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "\n",
    "    x = cbam_block(x,16)\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3),strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "\n",
    "    x = cbam_block(x,32)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units=16)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    out = Dense(units=output_size)(x)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b568ef4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.361658Z",
     "start_time": "2024-06-10T10:23:54.537411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 9, 9, 5)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 16)     736         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 16)     64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 7, 7, 16)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 7, 7, 16)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 16)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 16)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_2 (TFOpLambda)         (None, 2, 16)        0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2, 8)         136         tf.stack_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2, 16)        144         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 16)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 16)           0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 16)     0           tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 7, 7, 16)     0           reshape_1[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 7, 7)         0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max_1 (TFOpLambd (None, 7, 7)         0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_3 (TFOpLambda)         (None, 7, 7, 2)      0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.reduce_max_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 1)      50          tf.stack_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 7, 7, 16)     0           conv2d_2[0][0]                   \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 32)     4640        tf.math.multiply_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 5, 5, 32)     128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5, 5, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 5, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_4 (TFOpLambda)         (None, 2, 32)        0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2, 16)        528         tf.stack_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2, 32)        544         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLambd (None, 32)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_2 (TFOpLambda)  (None, 32)           0           tf.math.reduce_sum_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 32)     0           tf.math.sigmoid_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 5, 5, 32)     0           reshape_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_2 (TFOpLamb (None, 5, 5)         0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max_2 (TFOpLambd (None, 5, 5)         0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_5 (TFOpLambda)         (None, 5, 5, 2)      0           tf.math.reduce_mean_2[0][0]      \n",
      "                                                                 tf.math.reduce_max_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 5, 5, 1)      50          tf.stack_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 5, 5, 32)     0           conv2d_4[0][0]                   \n",
      "                                                                 tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 800)          0           tf.math.multiply_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           12816       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            17          activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,853\n",
      "Trainable params: 19,757\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5656463b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.366650Z",
     "start_time": "2024-06-10T10:23:59.362656Z"
    }
   },
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0005\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# checkpoint_path='./CNN_model_30.h5'\n",
    "# keras_callbacks   = [\n",
    "#       EarlyStopping(monitor='val_loss', patience=30, mode='min', min_delta=0.001),\n",
    "#       ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2737bb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.370643Z",
     "start_time": "2024-06-10T10:23:59.367648Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_epochs = 1000\n",
    "# batch_size = 10240\n",
    "\n",
    "# history = model.fit(x_train, y_train[:,14:15], validation_data=(x_val,y_val[:,14:15]),\n",
    "#                     epochs=num_epochs, batch_size=batch_size, verbose=2, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078e70b",
   "metadata": {},
   "source": [
    "## 网格搜索交叉验证寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fe983fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.374639Z",
     "start_time": "2024-06-10T10:23:59.371642Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# model = KerasRegressor(build_fn=create_model,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d66f9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.378631Z",
     "start_time": "2024-06-10T10:23:59.375635Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'neurons1': [16,32,64,128],\n",
    "#     'neurons2': [32,64,128,256],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e91bcc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.382624Z",
     "start_time": "2024-06-10T10:23:59.379629Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # 使用GridSearchCV进行交叉验证并搜索最佳参数组合：\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid_search.fit(x_train, y_train[:,14:15],epochs=100,verbose=2,batch_size=10240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "482bf93d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.386617Z",
     "start_time": "2024-06-10T10:23:59.383622Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8c413",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb9e990b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:23:59.391614Z",
     "start_time": "2024-06-10T10:23:59.387616Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_CNN(x_train,y_train,x_val,y_val,name):\n",
    "    # 创建网络\n",
    "    model = create_model()\n",
    "    # 编译网络\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    checkpoint_path=name\n",
    "    keras_callbacks   = [\n",
    "          EarlyStopping(monitor='val_loss', patience=30, mode='min', min_delta=0.001),\n",
    "          ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "    ]\n",
    "    model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
    "                    epochs=1000, batch_size=10240, verbose=2, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd30c7de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:32:46.136271Z",
     "start_time": "2024-06-10T10:35:47.581426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "836/836 - 29s - loss: 0.0608 - val_loss: 0.0238\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0133 - val_loss: 0.0077\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0051 - val_loss: 0.0123\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0048 - val_loss: 0.0092\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0046 - val_loss: 0.0120\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0045 - val_loss: 0.0122\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0043 - val_loss: 0.0130\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0042 - val_loss: 0.0148\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0042 - val_loss: 0.0157\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0041 - val_loss: 0.0168\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0040 - val_loss: 0.0218\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0039 - val_loss: 0.0219\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0039 - val_loss: 0.0164\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0037 - val_loss: 0.0178\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0037 - val_loss: 0.0179\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0037 - val_loss: 0.0235\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0037 - val_loss: 0.0203\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0037 - val_loss: 0.0210\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0036 - val_loss: 0.0160\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0036 - val_loss: 0.0235\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0036 - val_loss: 0.0280\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0035 - val_loss: 0.0247\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0034 - val_loss: 0.0243\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0034 - val_loss: 0.0263\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0034 - val_loss: 0.0269\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0034 - val_loss: 0.0247\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0034 - val_loss: 0.0270\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0033 - val_loss: 0.0209\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0033 - val_loss: 0.0335\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0033 - val_loss: 0.0244\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0033 - val_loss: 0.0278\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0033 - val_loss: 0.0288\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0770 - val_loss: 0.0361\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0202 - val_loss: 0.0164\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0084 - val_loss: 0.0097\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0082 - val_loss: 0.0118\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0078 - val_loss: 0.0133\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0075 - val_loss: 0.0166\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0075 - val_loss: 0.0115\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0074 - val_loss: 0.0113\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0074 - val_loss: 0.0128\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0073 - val_loss: 0.0096\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0072 - val_loss: 0.0110\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0072 - val_loss: 0.0109\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0114\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0095\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0105\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0104\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0090\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0070 - val_loss: 0.0108\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 1/1000\n",
      "836/836 - 33s - loss: 0.0814 - val_loss: 0.0341\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0257 - val_loss: 0.0182\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0091 - val_loss: 0.0170\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0126\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0087 - val_loss: 0.0195\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0086 - val_loss: 0.0252\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0085 - val_loss: 0.0125\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0085 - val_loss: 0.0188\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0084 - val_loss: 0.0213\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0083 - val_loss: 0.0155\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0083 - val_loss: 0.0266\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0083 - val_loss: 0.0209\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0082 - val_loss: 0.0207\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0082 - val_loss: 0.0191\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0081 - val_loss: 0.0242\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0082 - val_loss: 0.0272\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0081 - val_loss: 0.0349\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0081 - val_loss: 0.0228\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0286\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0081 - val_loss: 0.0268\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0268\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0252\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0292\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0264\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0330\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0080 - val_loss: 0.0293\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0079 - val_loss: 0.0287\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0079 - val_loss: 0.0285\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0079 - val_loss: 0.0265\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0766 - val_loss: 0.0371\n",
      "Epoch 2/1000\n",
      "836/836 - 27s - loss: 0.0239 - val_loss: 0.0196\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0161 - val_loss: 0.0127\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0098 - val_loss: 0.0145\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0093 - val_loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0093 - val_loss: 0.0180\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0091 - val_loss: 0.0157\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0092 - val_loss: 0.0130\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0090 - val_loss: 0.0174\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0090 - val_loss: 0.0183\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0189\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0158\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0162\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0185\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0088 - val_loss: 0.0147\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0089 - val_loss: 0.0159\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0088 - val_loss: 0.0137\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0088 - val_loss: 0.0164\n",
      "Epoch 34/1000\n",
      "836/836 - 27s - loss: 0.0088 - val_loss: 0.0166\n",
      "Epoch 35/1000\n",
      "836/836 - 27s - loss: 0.0087 - val_loss: 0.0198\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0087 - val_loss: 0.0193\n",
      "Epoch 1/1000\n",
      "836/836 - 39s - loss: 0.0785 - val_loss: 0.0367\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0255 - val_loss: 0.0192\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0179 - val_loss: 0.0162\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0151 - val_loss: 0.0190\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0130 - val_loss: 0.0179\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0127 - val_loss: 0.0180\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0120 - val_loss: 0.0171\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0120 - val_loss: 0.0178\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0116 - val_loss: 0.0154\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0114 - val_loss: 0.0157\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0114 - val_loss: 0.0167\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0113 - val_loss: 0.0169\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0113 - val_loss: 0.0153\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0113 - val_loss: 0.0153\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0112 - val_loss: 0.0143\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0140\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0144\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0151\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0157\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0160\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0150\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0155\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0110 - val_loss: 0.0156\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0144\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0110 - val_loss: 0.0151\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0148\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 1/1000\n",
      "836/836 - 29s - loss: 0.0885 - val_loss: 0.0408\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0312 - val_loss: 0.0229\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0217 - val_loss: 0.0181\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0187 - val_loss: 0.0164\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0174 - val_loss: 0.0163\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0167 - val_loss: 0.0179\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0162 - val_loss: 0.0156\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0158 - val_loss: 0.0165\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0146 - val_loss: 0.0162\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0140 - val_loss: 0.0162\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0140 - val_loss: 0.0157\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0140 - val_loss: 0.0181\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0163\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0189\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0171\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0137 - val_loss: 0.0188\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0788 - val_loss: 0.0366\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0242\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0234 - val_loss: 0.0224\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0213 - val_loss: 0.0199\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0187 - val_loss: 0.0191\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0184 - val_loss: 0.0190\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0181 - val_loss: 0.0211\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0177 - val_loss: 0.0189\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0174 - val_loss: 0.0214\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0169 - val_loss: 0.0195\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0166 - val_loss: 0.0199\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0166 - val_loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0165 - val_loss: 0.0233\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0164 - val_loss: 0.0251\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0164 - val_loss: 0.0224\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0163 - val_loss: 0.0233\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0163 - val_loss: 0.0195\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0162 - val_loss: 0.0226\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0162 - val_loss: 0.0189\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0162 - val_loss: 0.0216\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0161 - val_loss: 0.0190\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0161 - val_loss: 0.0223\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0161 - val_loss: 0.0214\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0161 - val_loss: 0.0206\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0160 - val_loss: 0.0194\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0160 - val_loss: 0.0232\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0160 - val_loss: 0.0205\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0160 - val_loss: 0.0208\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0160 - val_loss: 0.0187\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0159 - val_loss: 0.0248\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0819 - val_loss: 0.0407\n",
      "Epoch 2/1000\n",
      "836/836 - 27s - loss: 0.0330 - val_loss: 0.0281\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0260 - val_loss: 0.0278\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0235 - val_loss: 0.0216\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0222 - val_loss: 0.0197\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0214 - val_loss: 0.0196\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0206 - val_loss: 0.0217\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0202 - val_loss: 0.0209\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0200 - val_loss: 0.0188\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0198 - val_loss: 0.0221\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0195 - val_loss: 0.0200\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0194 - val_loss: 0.0218\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0188 - val_loss: 0.0200\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0188 - val_loss: 0.0250\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0187 - val_loss: 0.0222\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0186 - val_loss: 0.0211\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0185 - val_loss: 0.0220\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0184 - val_loss: 0.0216\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0183 - val_loss: 0.0193\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0182 - val_loss: 0.0212\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0183 - val_loss: 0.0213\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0182 - val_loss: 0.0209\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0181 - val_loss: 0.0196\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0180 - val_loss: 0.0223\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0180 - val_loss: 0.0196\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0179 - val_loss: 0.0216\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0877 - val_loss: 0.0456\n",
      "Epoch 2/1000\n",
      "836/836 - 27s - loss: 0.0361 - val_loss: 0.0314\n",
      "Epoch 3/1000\n",
      "836/836 - 27s - loss: 0.0291 - val_loss: 0.0271\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0264 - val_loss: 0.0247\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0249 - val_loss: 0.0316\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0239 - val_loss: 0.0275\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0231 - val_loss: 0.0262\n",
      "Epoch 8/1000\n",
      "836/836 - 27s - loss: 0.0226 - val_loss: 0.0240\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0222 - val_loss: 0.0214\n",
      "Epoch 10/1000\n",
      "836/836 - 27s - loss: 0.0218 - val_loss: 0.0214\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0215 - val_loss: 0.0221\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0213 - val_loss: 0.0249\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0209 - val_loss: 0.0269\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0208 - val_loss: 0.0229\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0206 - val_loss: 0.0224\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0205 - val_loss: 0.0224\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0203 - val_loss: 0.0239\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0201 - val_loss: 0.0233\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0201 - val_loss: 0.0236\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0199 - val_loss: 0.0229\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0199 - val_loss: 0.0223\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0198 - val_loss: 0.0225\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0198 - val_loss: 0.0278\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0197 - val_loss: 0.0229\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0197 - val_loss: 0.0233\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0196 - val_loss: 0.0259\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0195 - val_loss: 0.0233\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0195 - val_loss: 0.0225\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0194 - val_loss: 0.0208\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0193 - val_loss: 0.0250\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0193 - val_loss: 0.0273\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0193 - val_loss: 0.0248\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0192 - val_loss: 0.0241\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0191 - val_loss: 0.0297\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0192 - val_loss: 0.0269\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.0817 - val_loss: 0.0444\n",
      "Epoch 2/1000\n",
      "836/836 - 27s - loss: 0.0372 - val_loss: 0.0332\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0274\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0273 - val_loss: 0.0257\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0259 - val_loss: 0.0311\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0249 - val_loss: 0.0237\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0238 - val_loss: 0.0257\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0235 - val_loss: 0.0277\n",
      "Epoch 10/1000\n",
      "836/836 - 27s - loss: 0.0231 - val_loss: 0.0269\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0229 - val_loss: 0.0224\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0227 - val_loss: 0.0234\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0225 - val_loss: 0.0262\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0222 - val_loss: 0.0244\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0221 - val_loss: 0.0248\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0220 - val_loss: 0.0230\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0220 - val_loss: 0.0273\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0218 - val_loss: 0.0249\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0217 - val_loss: 0.0238\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0217 - val_loss: 0.0231\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0216 - val_loss: 0.0223\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0215 - val_loss: 0.0249\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0215 - val_loss: 0.0253\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0214 - val_loss: 0.0233\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0214 - val_loss: 0.0242\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0213 - val_loss: 0.0265\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0213 - val_loss: 0.0277\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0212 - val_loss: 0.0283\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0212 - val_loss: 0.0256\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0211 - val_loss: 0.0259\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0211 - val_loss: 0.0256\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0211 - val_loss: 0.0243\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0210 - val_loss: 0.0249\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0210 - val_loss: 0.0285\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0210 - val_loss: 0.0262\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0209 - val_loss: 0.0229\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0209 - val_loss: 0.0262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0209 - val_loss: 0.0247\n",
      "Epoch 1/1000\n",
      "836/836 - 41s - loss: 0.0991 - val_loss: 0.0536\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0350\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0325 - val_loss: 0.0336\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0302 - val_loss: 0.0320\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0288 - val_loss: 0.0335\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0278 - val_loss: 0.0268\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0270 - val_loss: 0.0287\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0262 - val_loss: 0.0308\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0258 - val_loss: 0.0294\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0253 - val_loss: 0.0302\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0328\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0246 - val_loss: 0.0287\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0243 - val_loss: 0.0272\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0241 - val_loss: 0.0260\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0239 - val_loss: 0.0281\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0237 - val_loss: 0.0281\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0237 - val_loss: 0.0276\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0235 - val_loss: 0.0279\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0234 - val_loss: 0.0249\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0233 - val_loss: 0.0295\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0233 - val_loss: 0.0257\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0232 - val_loss: 0.0255\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0231 - val_loss: 0.0266\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0231 - val_loss: 0.0255\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0232 - val_loss: 0.0243\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0229 - val_loss: 0.0273\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0229 - val_loss: 0.0256\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0229 - val_loss: 0.0268\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0228 - val_loss: 0.0256\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0228 - val_loss: 0.0243\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0228 - val_loss: 0.0251\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0227 - val_loss: 0.0262\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0226 - val_loss: 0.0249\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0226 - val_loss: 0.0241\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0226 - val_loss: 0.0243\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0244\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0293\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0256\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0254\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0224 - val_loss: 0.0263\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0224 - val_loss: 0.0281\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0224 - val_loss: 0.0276\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0224 - val_loss: 0.0249\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0267\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0243\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0261\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 1/1000\n",
      "836/836 - 30s - loss: 0.1034 - val_loss: 0.0571\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0482 - val_loss: 0.0407\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0392 - val_loss: 0.0390\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0352 - val_loss: 0.0417\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0329 - val_loss: 0.0406\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0313 - val_loss: 0.0372\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0359\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0296 - val_loss: 0.0350\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0289 - val_loss: 0.0318\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0284 - val_loss: 0.0346\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0281 - val_loss: 0.0328\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0277 - val_loss: 0.0298\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0275 - val_loss: 0.0400\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0354\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0271 - val_loss: 0.0296\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0269 - val_loss: 0.0321\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0267 - val_loss: 0.0295\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0266 - val_loss: 0.0297\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0265 - val_loss: 0.0310\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0263 - val_loss: 0.0322\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0263 - val_loss: 0.0303\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0262 - val_loss: 0.0325\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0261 - val_loss: 0.0341\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0260 - val_loss: 0.0305\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0260 - val_loss: 0.0319\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0259 - val_loss: 0.0291\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0258 - val_loss: 0.0335\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0257 - val_loss: 0.0306\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0257 - val_loss: 0.0320\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0256 - val_loss: 0.0317\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0256 - val_loss: 0.0301\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0256 - val_loss: 0.0316\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0255 - val_loss: 0.0310\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0255 - val_loss: 0.0289\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0254 - val_loss: 0.0286\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0254 - val_loss: 0.0323\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0254 - val_loss: 0.0334\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0253 - val_loss: 0.0289\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0253 - val_loss: 0.0336\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0252 - val_loss: 0.0310\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0253 - val_loss: 0.0300\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0252 - val_loss: 0.0310\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0251 - val_loss: 0.0318\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0251 - val_loss: 0.0341\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0251 - val_loss: 0.0319\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0250 - val_loss: 0.0287\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0251 - val_loss: 0.0339\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0250 - val_loss: 0.0311\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0250 - val_loss: 0.0319\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0250 - val_loss: 0.0298\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0296\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0304\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0316\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0327\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0299\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0249 - val_loss: 0.0296\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0329\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0327\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0299\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0300\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0300\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0350\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0306\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0247 - val_loss: 0.0338\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0247 - val_loss: 0.0334\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1195 - val_loss: 0.0761\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0607 - val_loss: 0.0722\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0480 - val_loss: 0.0582\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0424 - val_loss: 0.0457\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0392 - val_loss: 0.0484\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0374 - val_loss: 0.0516\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0412\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0427\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0346 - val_loss: 0.0456\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0390\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0334 - val_loss: 0.0513\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0435\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0441\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0444\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0324 - val_loss: 0.0478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0469\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0410\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0319 - val_loss: 0.0465\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0455\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0429\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0315 - val_loss: 0.0367\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0364\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0396\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0439\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0408\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0439\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0353\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0416\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0440\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0372\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0416\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0378\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0407\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0387\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0381\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0302 - val_loss: 0.0392\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0378\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0361\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0396\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0367\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0403\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0363\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0358\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0379\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0350\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0433\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0356\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0368\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0384\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0352\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0364\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0370\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0336\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0349\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0392\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0350\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0358\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0388\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0359\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0361\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0367\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0377\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0356\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0368\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0332\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0358\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0355\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0361\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0353\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0357\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0348\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0349\n",
      "Epoch 76/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0335\n",
      "Epoch 77/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0363\n",
      "Epoch 78/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0330\n",
      "Epoch 79/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 80/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0373\n",
      "Epoch 81/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0368\n",
      "Epoch 82/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0328\n",
      "Epoch 83/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0350\n",
      "Epoch 84/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0383\n",
      "Epoch 85/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0328\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1211 - val_loss: 0.0740\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0635 - val_loss: 0.0597\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0516 - val_loss: 0.0512\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0468 - val_loss: 0.0471\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0442 - val_loss: 0.0482\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0425 - val_loss: 0.0485\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0452\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0479\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0476\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0459\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0388 - val_loss: 0.0402\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0383 - val_loss: 0.0473\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0380 - val_loss: 0.0469\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0416\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0374 - val_loss: 0.0454\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0416\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0435\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0434\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0467\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0432\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0421\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0423\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0417\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0421\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0415\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0348 - val_loss: 0.0398\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0347 - val_loss: 0.0397\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0347 - val_loss: 0.0435\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0344 - val_loss: 0.0356\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0345 - val_loss: 0.0405\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0343 - val_loss: 0.0393\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0342 - val_loss: 0.0395\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0342 - val_loss: 0.0363\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0369\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0409\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0339 - val_loss: 0.0406\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0338 - val_loss: 0.0388\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0337 - val_loss: 0.0414\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0337 - val_loss: 0.0411\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0350\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0411\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0335 - val_loss: 0.0418\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0335 - val_loss: 0.0384\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0446\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0358\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0376\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0403\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0392\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0442\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0348\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0412\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0399\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0400\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0385\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0329 - val_loss: 0.0373\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0416\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0344\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0329 - val_loss: 0.0419\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0382\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0410\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0437\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0369\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0355\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0342\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0363\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0359\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0381\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0346\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0384\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1231 - val_loss: 0.0770\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0653 - val_loss: 0.0706\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0537 - val_loss: 0.0706\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0490 - val_loss: 0.0587\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0461 - val_loss: 0.0668\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0442 - val_loss: 0.0487\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0430 - val_loss: 0.0610\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0420 - val_loss: 0.0652\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0414 - val_loss: 0.0547\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0407 - val_loss: 0.0525\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0403 - val_loss: 0.0628\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0399 - val_loss: 0.0563\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0394 - val_loss: 0.0514\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0391 - val_loss: 0.0479\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0389 - val_loss: 0.0637\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0386 - val_loss: 0.0512\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0383 - val_loss: 0.0474\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0381 - val_loss: 0.0536\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0379 - val_loss: 0.0476\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0551\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0375 - val_loss: 0.0529\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0374 - val_loss: 0.0513\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0372 - val_loss: 0.0414\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0372 - val_loss: 0.0448\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0432\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0439\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0469\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0462\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0455\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0464\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0525\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0445\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0364 - val_loss: 0.0404\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0494\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0434\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0421\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0497\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0360 - val_loss: 0.0452\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0401\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0432\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0358 - val_loss: 0.0444\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0502\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0542\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0405\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0418\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0429\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0424\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0469\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0447\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0432\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0399\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0435\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0440\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0353 - val_loss: 0.0506\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0353 - val_loss: 0.0455\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0353 - val_loss: 0.0415\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0458\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0479\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0528\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0439\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0350 - val_loss: 0.0428\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0350 - val_loss: 0.0466\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0419\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0350 - val_loss: 0.0463\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0350 - val_loss: 0.0391\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0454\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0420\n",
      "Epoch 1/1000\n",
      "836/836 - 39s - loss: 0.1246 - val_loss: 0.0812\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0667 - val_loss: 0.0662\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0557 - val_loss: 0.0562\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0514 - val_loss: 0.0588\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0488 - val_loss: 0.0565\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0469 - val_loss: 0.0677\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0454 - val_loss: 0.0455\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0444 - val_loss: 0.0524\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0435 - val_loss: 0.0552\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0429 - val_loss: 0.0453\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0423 - val_loss: 0.0542\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0547\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0412 - val_loss: 0.0483\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0478\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0549\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0508\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0466\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0506\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0394 - val_loss: 0.0540\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0392 - val_loss: 0.0450\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0391 - val_loss: 0.0440\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0389 - val_loss: 0.0529\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0387 - val_loss: 0.0431\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0386 - val_loss: 0.0440\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0385 - val_loss: 0.0467\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0384 - val_loss: 0.0451\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0382 - val_loss: 0.0452\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0381 - val_loss: 0.0535\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0380 - val_loss: 0.0557\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0379 - val_loss: 0.0468\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0378 - val_loss: 0.0461\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0378 - val_loss: 0.0454\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0377 - val_loss: 0.0415\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0376 - val_loss: 0.0505\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0375 - val_loss: 0.0484\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0374 - val_loss: 0.0423\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0374 - val_loss: 0.0497\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0373 - val_loss: 0.0484\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0372 - val_loss: 0.0525\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0372 - val_loss: 0.0544\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0371 - val_loss: 0.0458\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0370 - val_loss: 0.0446\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0370 - val_loss: 0.0464\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0370 - val_loss: 0.0496\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0369 - val_loss: 0.0642\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0369 - val_loss: 0.0444\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0367 - val_loss: 0.0440\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0368 - val_loss: 0.0480\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0367 - val_loss: 0.0445\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0366 - val_loss: 0.0468\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0366 - val_loss: 0.0523\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0489\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0526\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0471\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0514\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0364 - val_loss: 0.0475\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0363 - val_loss: 0.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0363 - val_loss: 0.0478\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0362 - val_loss: 0.0471\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0362 - val_loss: 0.0487\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0361 - val_loss: 0.0421\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0361 - val_loss: 0.0440\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0360 - val_loss: 0.0462\n",
      "Epoch 1/1000\n",
      "836/836 - 30s - loss: 0.1207 - val_loss: 0.0789\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0658 - val_loss: 0.0738\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0540 - val_loss: 0.0614\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0490 - val_loss: 0.0628\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0464 - val_loss: 0.0730\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0448 - val_loss: 0.0707\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0436 - val_loss: 0.0638\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0426 - val_loss: 0.0578\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0675\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0410 - val_loss: 0.0541\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0581\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0583\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0393 - val_loss: 0.0538\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0390 - val_loss: 0.0481\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0387 - val_loss: 0.0504\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0383 - val_loss: 0.0580\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0381 - val_loss: 0.0564\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0378 - val_loss: 0.0581\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0375 - val_loss: 0.0563\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0374 - val_loss: 0.0616\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0372 - val_loss: 0.0505\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0370 - val_loss: 0.0569\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0368 - val_loss: 0.0514\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0367 - val_loss: 0.0573\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0366 - val_loss: 0.0524\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0364 - val_loss: 0.0591\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0363 - val_loss: 0.0502\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0362 - val_loss: 0.0535\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0361 - val_loss: 0.0513\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0360 - val_loss: 0.0539\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0359 - val_loss: 0.0482\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0358 - val_loss: 0.0576\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0357 - val_loss: 0.0519\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0357 - val_loss: 0.0483\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0355 - val_loss: 0.0588\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0355 - val_loss: 0.0573\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0355 - val_loss: 0.0460\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0354 - val_loss: 0.0546\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0354 - val_loss: 0.0500\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0353 - val_loss: 0.0445\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0353 - val_loss: 0.0517\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0352 - val_loss: 0.0625\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0352 - val_loss: 0.0461\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0351 - val_loss: 0.0481\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0351 - val_loss: 0.0549\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0350 - val_loss: 0.0490\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0349 - val_loss: 0.0494\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0350 - val_loss: 0.0575\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0349 - val_loss: 0.0521\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0349 - val_loss: 0.0561\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0348 - val_loss: 0.0486\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0348 - val_loss: 0.0534\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0348 - val_loss: 0.0469\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0347 - val_loss: 0.0468\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0347 - val_loss: 0.0474\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0500\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0484\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0499\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0345 - val_loss: 0.0478\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0513\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0345 - val_loss: 0.0484\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0345 - val_loss: 0.0488\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0345 - val_loss: 0.0454\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0468\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0503\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0498\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0343 - val_loss: 0.0464\n",
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0343 - val_loss: 0.0516\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0343 - val_loss: 0.0457\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0342 - val_loss: 0.0464\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1198 - val_loss: 0.0807\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0622 - val_loss: 0.0604\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0522 - val_loss: 0.0558\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0477 - val_loss: 0.0561\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0447 - val_loss: 0.0445\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0427 - val_loss: 0.0510\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0474\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0511\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0394 - val_loss: 0.0514\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0387 - val_loss: 0.0448\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0382 - val_loss: 0.0510\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0450\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0372 - val_loss: 0.0426\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0479\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0441\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0386\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0409\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0426\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0414\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0418\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0425\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0348 - val_loss: 0.0422\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0346 - val_loss: 0.0420\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0344 - val_loss: 0.0538\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0344 - val_loss: 0.0428\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0343 - val_loss: 0.0374\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0341 - val_loss: 0.0476\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0400\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0339 - val_loss: 0.0433\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0338 - val_loss: 0.0389\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0470\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0439\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0335 - val_loss: 0.0417\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0410\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0373\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0436\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0445\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0392\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0423\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0438\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0329 - val_loss: 0.0427\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0396\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0442\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0407\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0411\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0388\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0409\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0528\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0399\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0324 - val_loss: 0.0379\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0324 - val_loss: 0.0394\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0419\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0387\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0383\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0322 - val_loss: 0.0443\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0322 - val_loss: 0.0424\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1191 - val_loss: 0.0899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0615 - val_loss: 0.0671\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0513 - val_loss: 0.0666\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0467 - val_loss: 0.0771\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0441 - val_loss: 0.0609\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0687\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0406 - val_loss: 0.0580\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0395 - val_loss: 0.0691\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0385 - val_loss: 0.0544\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0378 - val_loss: 0.0537\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0372 - val_loss: 0.0639\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0614\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0547\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0504\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0537\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0457\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0350 - val_loss: 0.0495\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0346 - val_loss: 0.0513\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0344 - val_loss: 0.0596\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0341 - val_loss: 0.0538\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0338 - val_loss: 0.0544\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0585\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0575\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0576\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0329 - val_loss: 0.0529\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0515\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0706\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0570\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0510\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0322 - val_loss: 0.0497\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0537\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0320 - val_loss: 0.0579\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0319 - val_loss: 0.0533\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0605\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0317 - val_loss: 0.0637\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0564\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0315 - val_loss: 0.0597\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0579\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0653\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0434\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0312 - val_loss: 0.0558\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0575\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0508\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0712\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0500\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0545\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0555\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0481\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0531\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0518\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0505\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0305 - val_loss: 0.0505\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0532\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0388\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0543\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0695\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0508\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0302 - val_loss: 0.0628\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0302 - val_loss: 0.0496\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0302 - val_loss: 0.0610\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0497\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0622\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0559\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0539\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0543\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0529\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0532\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0579\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0588\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0621\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0492\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0611\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0488\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0651\n",
      "Epoch 76/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0555\n",
      "Epoch 77/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0654\n",
      "Epoch 78/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0639\n",
      "Epoch 79/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0505\n",
      "Epoch 80/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0479\n",
      "Epoch 81/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0523\n",
      "Epoch 82/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0558\n",
      "Epoch 83/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0489\n",
      "Epoch 84/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0478\n",
      "Epoch 85/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0464\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1361 - val_loss: 0.0831\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0676 - val_loss: 0.0611\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0545 - val_loss: 0.0568\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0487 - val_loss: 0.0499\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0454 - val_loss: 0.0519\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0434 - val_loss: 0.0493\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0419 - val_loss: 0.0480\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0487\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0465\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0390 - val_loss: 0.0451\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0383 - val_loss: 0.0439\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0378 - val_loss: 0.0558\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0440\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0477\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0471\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0416\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0358 - val_loss: 0.0410\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0503\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0353 - val_loss: 0.0400\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0466\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0348 - val_loss: 0.0497\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0346 - val_loss: 0.0468\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0345 - val_loss: 0.0465\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0343 - val_loss: 0.0492\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0341 - val_loss: 0.0394\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0466\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0337 - val_loss: 0.0432\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0336 - val_loss: 0.0433\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0334 - val_loss: 0.0421\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0334 - val_loss: 0.0484\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0500\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0331 - val_loss: 0.0406\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0448\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0467\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0427\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0479\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0487\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0324 - val_loss: 0.0431\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0415\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0467\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0411\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0465\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0443\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0320 - val_loss: 0.0418\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0320 - val_loss: 0.0380\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0319 - val_loss: 0.0444\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0387\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0427\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0317 - val_loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0317 - val_loss: 0.0441\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0390\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0315 - val_loss: 0.0456\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0473\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0402\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0492\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0460\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0312 - val_loss: 0.0437\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0312 - val_loss: 0.0479\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0394\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0462\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0417\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0455\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0444\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0404\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0426\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0511\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0417\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0474\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0449\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0422\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0458\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0456\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0438\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0443\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0305 - val_loss: 0.0425\n",
      "Epoch 1/1000\n",
      "836/836 - 42s - loss: 0.1379 - val_loss: 0.0974\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0703 - val_loss: 0.0697\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0577 - val_loss: 0.0690\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0517 - val_loss: 0.0716\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0480 - val_loss: 0.0706\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0454 - val_loss: 0.0714\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0434 - val_loss: 0.0590\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0420 - val_loss: 0.0629\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0409 - val_loss: 0.0553\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0483\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0392 - val_loss: 0.0553\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0386 - val_loss: 0.0595\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0382 - val_loss: 0.0479\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0376 - val_loss: 0.0477\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0372 - val_loss: 0.0475\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0368 - val_loss: 0.0560\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0365 - val_loss: 0.0472\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0362 - val_loss: 0.0434\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0359 - val_loss: 0.0479\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0357 - val_loss: 0.0429\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0355 - val_loss: 0.0446\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0352 - val_loss: 0.0441\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0351 - val_loss: 0.0466\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0349 - val_loss: 0.0440\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0348 - val_loss: 0.0635\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0569\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0450\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0343 - val_loss: 0.0481\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0342 - val_loss: 0.0422\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0340 - val_loss: 0.0409\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0339 - val_loss: 0.0460\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0337 - val_loss: 0.0428\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0337 - val_loss: 0.0457\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0336 - val_loss: 0.0360\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0335 - val_loss: 0.0388\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0334 - val_loss: 0.0442\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0333 - val_loss: 0.0425\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0332 - val_loss: 0.0434\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0331 - val_loss: 0.0432\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0331 - val_loss: 0.0411\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0330 - val_loss: 0.0451\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0329 - val_loss: 0.0393\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0329 - val_loss: 0.0492\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0327 - val_loss: 0.0401\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0327 - val_loss: 0.0398\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0382\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0396\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0325 - val_loss: 0.0481\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0325 - val_loss: 0.0408\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0324 - val_loss: 0.0422\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0456\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0359\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0322 - val_loss: 0.0425\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0322 - val_loss: 0.0442\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0322 - val_loss: 0.0381\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0320 - val_loss: 0.0484\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0321 - val_loss: 0.0381\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0320 - val_loss: 0.0426\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0320 - val_loss: 0.0417\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0319 - val_loss: 0.0426\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0319 - val_loss: 0.0474\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0318 - val_loss: 0.0360\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0318 - val_loss: 0.0445\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0318 - val_loss: 0.0440\n",
      "Epoch 1/1000\n",
      "836/836 - 29s - loss: 0.1255 - val_loss: 0.0891\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0640 - val_loss: 0.0980\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0532 - val_loss: 0.0686\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0485 - val_loss: 0.0666\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0458 - val_loss: 0.0621\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0438 - val_loss: 0.0641\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0424 - val_loss: 0.0501\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0413 - val_loss: 0.0548\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0403 - val_loss: 0.0475\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0531\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0389 - val_loss: 0.0505\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0382 - val_loss: 0.0472\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0376 - val_loss: 0.0584\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0371 - val_loss: 0.0481\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0366 - val_loss: 0.0514\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0362 - val_loss: 0.0510\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0358 - val_loss: 0.0456\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0353 - val_loss: 0.0520\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0350 - val_loss: 0.0414\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0346 - val_loss: 0.0486\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0547\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0341 - val_loss: 0.0486\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0339 - val_loss: 0.0528\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0336 - val_loss: 0.0482\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0334 - val_loss: 0.0444\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0332 - val_loss: 0.0520\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0332 - val_loss: 0.0422\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0329 - val_loss: 0.0420\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0328 - val_loss: 0.0460\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0461\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0325 - val_loss: 0.0486\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0467\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0467\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0321 - val_loss: 0.0534\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0321 - val_loss: 0.0537\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0320 - val_loss: 0.0481\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0319 - val_loss: 0.0561\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0318 - val_loss: 0.0461\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0317 - val_loss: 0.0463\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0317 - val_loss: 0.0383\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0316 - val_loss: 0.0432\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0315 - val_loss: 0.0457\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0314 - val_loss: 0.0452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0314 - val_loss: 0.0433\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0313 - val_loss: 0.0456\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0312 - val_loss: 0.0441\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0312 - val_loss: 0.0534\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0311 - val_loss: 0.0489\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0311 - val_loss: 0.0433\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0310 - val_loss: 0.0450\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0310 - val_loss: 0.0482\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0309 - val_loss: 0.0401\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0309 - val_loss: 0.0469\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0308 - val_loss: 0.0451\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0308 - val_loss: 0.0488\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0418\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0381\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0447\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0306 - val_loss: 0.0440\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0306 - val_loss: 0.0498\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0305 - val_loss: 0.0479\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0306 - val_loss: 0.0499\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0305 - val_loss: 0.0518\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0305 - val_loss: 0.0446\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0304 - val_loss: 0.0457\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0304 - val_loss: 0.0449\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0493\n",
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0435\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0533\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0302 - val_loss: 0.0437\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1317 - val_loss: 0.0781\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0657 - val_loss: 0.0659\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0540 - val_loss: 0.0639\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0488 - val_loss: 0.0552\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0456 - val_loss: 0.0598\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0438 - val_loss: 0.0518\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0423 - val_loss: 0.0474\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0448\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0401 - val_loss: 0.0520\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0484\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0386 - val_loss: 0.0448\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0379 - val_loss: 0.0450\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0434\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0369 - val_loss: 0.0419\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0435\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0386\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0439\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0412\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0434\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0348 - val_loss: 0.0373\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0345 - val_loss: 0.0384\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0343 - val_loss: 0.0396\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0340 - val_loss: 0.0379\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0337 - val_loss: 0.0389\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0335 - val_loss: 0.0424\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0333 - val_loss: 0.0391\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0351\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0357\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0328 - val_loss: 0.0384\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0369\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0325 - val_loss: 0.0389\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0352\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0322 - val_loss: 0.0361\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0404\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0320 - val_loss: 0.0370\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0368\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0317 - val_loss: 0.0400\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0389\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0383\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0314 - val_loss: 0.0352\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0428\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0380\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0312 - val_loss: 0.0381\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0363\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0379\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0375\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0366\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0308 - val_loss: 0.0354\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0345\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0398\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0468\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0372\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0349\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0423\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0348\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0362\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0419\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1239 - val_loss: 0.1438\n",
      "Epoch 2/1000\n",
      "836/836 - 27s - loss: 0.0623 - val_loss: 0.0943\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0521 - val_loss: 0.0669\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0475 - val_loss: 0.0570\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0446 - val_loss: 0.0586\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0769\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0518\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0496\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0390 - val_loss: 0.0591\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0382 - val_loss: 0.0486\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0376 - val_loss: 0.0546\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0369 - val_loss: 0.0454\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0570\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0592\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0428\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0469\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0345 - val_loss: 0.0360\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0341 - val_loss: 0.0392\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0338 - val_loss: 0.0390\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0335 - val_loss: 0.0466\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0332 - val_loss: 0.0381\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0330 - val_loss: 0.0393\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0327 - val_loss: 0.0495\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0326 - val_loss: 0.0398\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0547\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0323 - val_loss: 0.0417\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0321 - val_loss: 0.0382\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0319 - val_loss: 0.0401\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0318 - val_loss: 0.0451\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0316 - val_loss: 0.0404\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0315 - val_loss: 0.0382\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0362\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0313 - val_loss: 0.0413\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0311 - val_loss: 0.0391\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0310 - val_loss: 0.0363\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0336\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0309 - val_loss: 0.0354\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0462\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0307 - val_loss: 0.0326\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0306 - val_loss: 0.0377\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0305 - val_loss: 0.0310\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0304 - val_loss: 0.0353\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0443\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0379\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0303 - val_loss: 0.0372\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0343\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0490\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0301 - val_loss: 0.0370\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0300 - val_loss: 0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0388\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0299 - val_loss: 0.0367\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0317\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0298 - val_loss: 0.0391\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0344\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0297 - val_loss: 0.0334\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0296 - val_loss: 0.0379\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0341\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0416\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0295 - val_loss: 0.0377\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0344\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0358\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0294 - val_loss: 0.0397\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0445\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0293 - val_loss: 0.0309\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0351\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0364\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0291 - val_loss: 0.0349\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0292 - val_loss: 0.0316\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0290 - val_loss: 0.0351\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1488 - val_loss: 0.1195\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0794 - val_loss: 0.0807\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0630 - val_loss: 0.0847\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0555 - val_loss: 0.0665\n",
      "Epoch 5/1000\n",
      "836/836 - 27s - loss: 0.0517 - val_loss: 0.0692\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0491 - val_loss: 0.0770\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0472 - val_loss: 0.0557\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0457 - val_loss: 0.0543\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0445 - val_loss: 0.0557\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0439 - val_loss: 0.0624\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0430 - val_loss: 0.0466\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0425 - val_loss: 0.0513\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0419 - val_loss: 0.0532\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0415 - val_loss: 0.0479\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0504\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0407 - val_loss: 0.0477\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0403 - val_loss: 0.0466\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0401 - val_loss: 0.0563\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0397 - val_loss: 0.0676\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0394 - val_loss: 0.0502\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0578\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0390 - val_loss: 0.0455\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0387 - val_loss: 0.0484\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0385 - val_loss: 0.0495\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0382 - val_loss: 0.0545\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0381 - val_loss: 0.0412\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0379 - val_loss: 0.0596\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0490\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0375 - val_loss: 0.0480\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0453\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0371 - val_loss: 0.0453\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0371 - val_loss: 0.0560\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0407\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0408\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0439\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0462\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0364 - val_loss: 0.0432\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0538\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0437\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0360 - val_loss: 0.0440\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0429\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0357 - val_loss: 0.0406\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0430\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0535\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0356 - val_loss: 0.0429\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0355 - val_loss: 0.0473\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0354 - val_loss: 0.0523\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0353 - val_loss: 0.0562\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0352 - val_loss: 0.0473\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0477\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0351 - val_loss: 0.0417\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0447\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0427\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0349 - val_loss: 0.0555\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0348 - val_loss: 0.0418\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0347 - val_loss: 0.0449\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.1571 - val_loss: 0.1203\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.0869 - val_loss: 0.1051\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0729 - val_loss: 0.0819\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0656 - val_loss: 0.0807\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0610 - val_loss: 0.0928\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0577 - val_loss: 0.1024\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0550 - val_loss: 0.0755\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0531 - val_loss: 0.0865\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0516 - val_loss: 0.0763\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0505 - val_loss: 0.0904\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0494 - val_loss: 0.0774\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0485 - val_loss: 0.0737\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0476 - val_loss: 0.0715\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0470 - val_loss: 0.0706\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0463 - val_loss: 0.0743\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0457 - val_loss: 0.0731\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0453 - val_loss: 0.0755\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0447 - val_loss: 0.0728\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0443 - val_loss: 0.0682\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0438 - val_loss: 0.0603\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0437 - val_loss: 0.0621\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0433 - val_loss: 0.0649\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0430 - val_loss: 0.0598\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0427 - val_loss: 0.0650\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0425 - val_loss: 0.0727\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0423 - val_loss: 0.0579\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0420 - val_loss: 0.0567\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0419 - val_loss: 0.0623\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0416 - val_loss: 0.0616\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0416 - val_loss: 0.0524\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0678\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0411 - val_loss: 0.0658\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0409 - val_loss: 0.0632\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0599\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0574\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0584\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0595\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0638\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0399 - val_loss: 0.0681\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0399 - val_loss: 0.0595\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0397 - val_loss: 0.0635\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0396 - val_loss: 0.0604\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0395 - val_loss: 0.0646\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0394 - val_loss: 0.0539\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0595\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0391 - val_loss: 0.0563\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0392 - val_loss: 0.0645\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0389 - val_loss: 0.0585\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0390 - val_loss: 0.0501\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0389 - val_loss: 0.0523\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0387 - val_loss: 0.0532\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0387 - val_loss: 0.0581\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0387 - val_loss: 0.0588\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0385 - val_loss: 0.0556\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0385 - val_loss: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0384 - val_loss: 0.0699\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0384 - val_loss: 0.0700\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0382 - val_loss: 0.0524\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0381 - val_loss: 0.0564\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0381 - val_loss: 0.0655\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0381 - val_loss: 0.0643\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0380 - val_loss: 0.0564\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0379 - val_loss: 0.0548\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0379 - val_loss: 0.0540\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0631\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0537\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0377 - val_loss: 0.0497\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0376 - val_loss: 0.0605\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0375 - val_loss: 0.0597\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0376 - val_loss: 0.0495\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0374 - val_loss: 0.0601\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0375 - val_loss: 0.0540\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0374 - val_loss: 0.0475\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0566\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0716\n",
      "Epoch 76/1000\n",
      "836/836 - 26s - loss: 0.0373 - val_loss: 0.0632\n",
      "Epoch 77/1000\n",
      "836/836 - 26s - loss: 0.0372 - val_loss: 0.0545\n",
      "Epoch 78/1000\n",
      "836/836 - 26s - loss: 0.0371 - val_loss: 0.0575\n",
      "Epoch 79/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0655\n",
      "Epoch 80/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0641\n",
      "Epoch 81/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0571\n",
      "Epoch 82/1000\n",
      "836/836 - 26s - loss: 0.0369 - val_loss: 0.0693\n",
      "Epoch 83/1000\n",
      "836/836 - 26s - loss: 0.0370 - val_loss: 0.0709\n",
      "Epoch 84/1000\n",
      "836/836 - 26s - loss: 0.0369 - val_loss: 0.0594\n",
      "Epoch 85/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0472\n",
      "Epoch 86/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0634\n",
      "Epoch 87/1000\n",
      "836/836 - 26s - loss: 0.0368 - val_loss: 0.0574\n",
      "Epoch 88/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0600\n",
      "Epoch 89/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0560\n",
      "Epoch 90/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0463\n",
      "Epoch 91/1000\n",
      "836/836 - 26s - loss: 0.0367 - val_loss: 0.0459\n",
      "Epoch 92/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0483\n",
      "Epoch 93/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0600\n",
      "Epoch 94/1000\n",
      "836/836 - 26s - loss: 0.0365 - val_loss: 0.0628\n",
      "Epoch 95/1000\n",
      "836/836 - 26s - loss: 0.0366 - val_loss: 0.0587\n",
      "Epoch 96/1000\n",
      "836/836 - 26s - loss: 0.0364 - val_loss: 0.0558\n",
      "Epoch 97/1000\n",
      "836/836 - 26s - loss: 0.0364 - val_loss: 0.0528\n",
      "Epoch 98/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0648\n",
      "Epoch 99/1000\n",
      "836/836 - 26s - loss: 0.0364 - val_loss: 0.0635\n",
      "Epoch 100/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0624\n",
      "Epoch 101/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0530\n",
      "Epoch 102/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0493\n",
      "Epoch 103/1000\n",
      "836/836 - 26s - loss: 0.0363 - val_loss: 0.0486\n",
      "Epoch 104/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0540\n",
      "Epoch 105/1000\n",
      "836/836 - 26s - loss: 0.0362 - val_loss: 0.0533\n",
      "Epoch 106/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0512\n",
      "Epoch 107/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0622\n",
      "Epoch 108/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0637\n",
      "Epoch 109/1000\n",
      "836/836 - 26s - loss: 0.0360 - val_loss: 0.0502\n",
      "Epoch 110/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0705\n",
      "Epoch 111/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0547\n",
      "Epoch 112/1000\n",
      "836/836 - 26s - loss: 0.0361 - val_loss: 0.0507\n",
      "Epoch 113/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0482\n",
      "Epoch 114/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0537\n",
      "Epoch 115/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0549\n",
      "Epoch 116/1000\n",
      "836/836 - 26s - loss: 0.0358 - val_loss: 0.0533\n",
      "Epoch 117/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0516\n",
      "Epoch 118/1000\n",
      "836/836 - 26s - loss: 0.0358 - val_loss: 0.0631\n",
      "Epoch 119/1000\n",
      "836/836 - 26s - loss: 0.0359 - val_loss: 0.0529\n",
      "Epoch 120/1000\n",
      "836/836 - 26s - loss: 0.0358 - val_loss: 0.0562\n",
      "Epoch 1/1000\n",
      "836/836 - 39s - loss: 0.1759 - val_loss: 0.1198\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.0946 - val_loss: 0.0849\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0761 - val_loss: 0.0905\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0674 - val_loss: 0.0969\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0622 - val_loss: 0.0757\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0590 - val_loss: 0.0696\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0567 - val_loss: 0.0999\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0552 - val_loss: 0.0878\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0537 - val_loss: 0.0583\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0526 - val_loss: 0.0640\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0517 - val_loss: 0.0561\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0509 - val_loss: 0.0692\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0503 - val_loss: 0.0723\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0496 - val_loss: 0.0564\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0492 - val_loss: 0.0852\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0487 - val_loss: 0.0635\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0481 - val_loss: 0.0546\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0478 - val_loss: 0.0614\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0473 - val_loss: 0.0639\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0470 - val_loss: 0.0565\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0465 - val_loss: 0.0545\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0465 - val_loss: 0.0510\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0460 - val_loss: 0.1020\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0458 - val_loss: 0.0546\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0454 - val_loss: 0.0488\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0453 - val_loss: 0.0513\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0449 - val_loss: 0.0576\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0448 - val_loss: 0.0512\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0446 - val_loss: 0.0526\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0443 - val_loss: 0.0495\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0441 - val_loss: 0.0689\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0439 - val_loss: 0.0592\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0438 - val_loss: 0.0522\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0435 - val_loss: 0.0592\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0433 - val_loss: 0.0915\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0432 - val_loss: 0.0501\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0430 - val_loss: 0.0477\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0428 - val_loss: 0.0509\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0427 - val_loss: 0.0500\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0426 - val_loss: 0.0596\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0425 - val_loss: 0.0496\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0422 - val_loss: 0.0609\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0421 - val_loss: 0.0491\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0421 - val_loss: 0.0453\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0418 - val_loss: 0.0657\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0418 - val_loss: 0.0454\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0463\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0416 - val_loss: 0.0529\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0414 - val_loss: 0.0522\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0413 - val_loss: 0.0489\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0413 - val_loss: 0.0468\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0411 - val_loss: 0.0475\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0411 - val_loss: 0.0500\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0410 - val_loss: 0.0496\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0615\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0436\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0407 - val_loss: 0.0601\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0406 - val_loss: 0.0562\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0405 - val_loss: 0.0476\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0643\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0529\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0516\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0609\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0403 - val_loss: 0.0514\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0681\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0635\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0504\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0445\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0508\n",
      "Epoch 71/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0564\n",
      "Epoch 72/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0863\n",
      "Epoch 73/1000\n",
      "836/836 - 25s - loss: 0.0397 - val_loss: 0.0448\n",
      "Epoch 74/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0552\n",
      "Epoch 75/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0438\n",
      "Epoch 76/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0504\n",
      "Epoch 77/1000\n",
      "836/836 - 25s - loss: 0.0395 - val_loss: 0.0450\n",
      "Epoch 78/1000\n",
      "836/836 - 25s - loss: 0.0394 - val_loss: 0.0495\n",
      "Epoch 79/1000\n",
      "836/836 - 25s - loss: 0.0394 - val_loss: 0.0626\n",
      "Epoch 80/1000\n",
      "836/836 - 25s - loss: 0.0393 - val_loss: 0.0574\n",
      "Epoch 81/1000\n",
      "836/836 - 25s - loss: 0.0393 - val_loss: 0.0674\n",
      "Epoch 82/1000\n",
      "836/836 - 25s - loss: 0.0393 - val_loss: 0.0473\n",
      "Epoch 83/1000\n",
      "836/836 - 25s - loss: 0.0392 - val_loss: 0.0573\n",
      "Epoch 84/1000\n",
      "836/836 - 25s - loss: 0.0392 - val_loss: 0.0469\n",
      "Epoch 85/1000\n",
      "836/836 - 25s - loss: 0.0391 - val_loss: 0.0454\n",
      "Epoch 86/1000\n",
      "836/836 - 25s - loss: 0.0391 - val_loss: 0.0623\n",
      "Epoch 1/1000\n",
      "836/836 - 30s - loss: 0.1957 - val_loss: 0.1308\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.1057 - val_loss: 0.0928\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0839 - val_loss: 0.0878\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0742 - val_loss: 0.0918\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0692 - val_loss: 0.0848\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0654 - val_loss: 0.0717\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0627 - val_loss: 0.0734\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0604 - val_loss: 0.0699\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0588 - val_loss: 0.0683\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0573 - val_loss: 0.0690\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0563 - val_loss: 0.0661\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0553 - val_loss: 0.0681\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0543 - val_loss: 0.0658\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0533 - val_loss: 0.0659\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0527 - val_loss: 0.0601\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0521 - val_loss: 0.0614\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0516 - val_loss: 0.0576\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0510 - val_loss: 0.0613\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0505 - val_loss: 0.0656\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0499 - val_loss: 0.0706\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0497 - val_loss: 0.0589\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0491 - val_loss: 0.0598\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0487 - val_loss: 0.0593\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0482 - val_loss: 0.0608\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0479 - val_loss: 0.0585\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0475 - val_loss: 0.0588\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0473 - val_loss: 0.0539\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0470 - val_loss: 0.0587\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0467 - val_loss: 0.0592\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0464 - val_loss: 0.0534\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0462 - val_loss: 0.0663\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0461 - val_loss: 0.0528\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0458 - val_loss: 0.0540\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0457 - val_loss: 0.0578\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0454 - val_loss: 0.0562\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0453 - val_loss: 0.0534\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0449 - val_loss: 0.0605\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0448 - val_loss: 0.0564\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0446 - val_loss: 0.0596\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0444 - val_loss: 0.0533\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0444 - val_loss: 0.0544\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0442 - val_loss: 0.0516\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0440 - val_loss: 0.0579\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0439 - val_loss: 0.0546\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0438 - val_loss: 0.0591\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0435 - val_loss: 0.0528\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0435 - val_loss: 0.0545\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0434 - val_loss: 0.0524\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0431 - val_loss: 0.0536\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0431 - val_loss: 0.0494\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0431 - val_loss: 0.0517\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0429 - val_loss: 0.0526\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0427 - val_loss: 0.0507\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0426 - val_loss: 0.0599\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0426 - val_loss: 0.0481\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0424 - val_loss: 0.0607\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0424 - val_loss: 0.0498\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0424 - val_loss: 0.0497\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0422 - val_loss: 0.0521\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0422 - val_loss: 0.0515\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0421 - val_loss: 0.0528\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0420 - val_loss: 0.0545\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0418 - val_loss: 0.0518\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0419 - val_loss: 0.0526\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0489\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0528\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0416 - val_loss: 0.0475\n",
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0415 - val_loss: 0.0520\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0414 - val_loss: 0.0483\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0414 - val_loss: 0.0508\n",
      "Epoch 71/1000\n",
      "836/836 - 25s - loss: 0.0413 - val_loss: 0.0501\n",
      "Epoch 72/1000\n",
      "836/836 - 25s - loss: 0.0412 - val_loss: 0.0521\n",
      "Epoch 73/1000\n",
      "836/836 - 25s - loss: 0.0413 - val_loss: 0.0491\n",
      "Epoch 74/1000\n",
      "836/836 - 25s - loss: 0.0412 - val_loss: 0.0470\n",
      "Epoch 75/1000\n",
      "836/836 - 25s - loss: 0.0412 - val_loss: 0.0500\n",
      "Epoch 76/1000\n",
      "836/836 - 25s - loss: 0.0410 - val_loss: 0.0487\n",
      "Epoch 77/1000\n",
      "836/836 - 25s - loss: 0.0410 - val_loss: 0.0483\n",
      "Epoch 78/1000\n",
      "836/836 - 25s - loss: 0.0409 - val_loss: 0.0484\n",
      "Epoch 79/1000\n",
      "836/836 - 25s - loss: 0.0409 - val_loss: 0.0471\n",
      "Epoch 80/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0492\n",
      "Epoch 81/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0511\n",
      "Epoch 82/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0516\n",
      "Epoch 83/1000\n",
      "836/836 - 25s - loss: 0.0406 - val_loss: 0.0456\n",
      "Epoch 84/1000\n",
      "836/836 - 25s - loss: 0.0407 - val_loss: 0.0494\n",
      "Epoch 85/1000\n",
      "836/836 - 25s - loss: 0.0406 - val_loss: 0.0463\n",
      "Epoch 86/1000\n",
      "836/836 - 25s - loss: 0.0405 - val_loss: 0.0462\n",
      "Epoch 87/1000\n",
      "836/836 - 25s - loss: 0.0405 - val_loss: 0.0539\n",
      "Epoch 88/1000\n",
      "836/836 - 25s - loss: 0.0405 - val_loss: 0.0477\n",
      "Epoch 89/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0485\n",
      "Epoch 90/1000\n",
      "836/836 - 25s - loss: 0.0404 - val_loss: 0.0465\n",
      "Epoch 91/1000\n",
      "836/836 - 25s - loss: 0.0403 - val_loss: 0.0498\n",
      "Epoch 92/1000\n",
      "836/836 - 25s - loss: 0.0402 - val_loss: 0.0486\n",
      "Epoch 93/1000\n",
      "836/836 - 25s - loss: 0.0403 - val_loss: 0.0483\n",
      "Epoch 94/1000\n",
      "836/836 - 25s - loss: 0.0402 - val_loss: 0.0494\n",
      "Epoch 95/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0544\n",
      "Epoch 96/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0481\n",
      "Epoch 97/1000\n",
      "836/836 - 25s - loss: 0.0401 - val_loss: 0.0490\n",
      "Epoch 98/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0482\n",
      "Epoch 99/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0462\n",
      "Epoch 100/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0536\n",
      "Epoch 101/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0460\n",
      "Epoch 102/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0499\n",
      "Epoch 103/1000\n",
      "836/836 - 25s - loss: 0.0399 - val_loss: 0.0471\n",
      "Epoch 104/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0479\n",
      "Epoch 105/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0515\n",
      "Epoch 106/1000\n",
      "836/836 - 25s - loss: 0.0398 - val_loss: 0.0470\n",
      "Epoch 107/1000\n",
      "836/836 - 25s - loss: 0.0397 - val_loss: 0.0465\n",
      "Epoch 108/1000\n",
      "836/836 - 25s - loss: 0.0397 - val_loss: 0.0460\n",
      "Epoch 109/1000\n",
      "836/836 - 25s - loss: 0.0397 - val_loss: 0.0515\n",
      "Epoch 110/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0480\n",
      "Epoch 111/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0474\n",
      "Epoch 112/1000\n",
      "836/836 - 25s - loss: 0.0396 - val_loss: 0.0478\n",
      "Epoch 113/1000\n",
      "836/836 - 25s - loss: 0.0395 - val_loss: 0.0469\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 - 32s - loss: 0.1952 - val_loss: 0.1293\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.1017 - val_loss: 0.1054\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0826 - val_loss: 0.0794\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0728 - val_loss: 0.0771\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0667 - val_loss: 0.0711\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0630 - val_loss: 0.0790\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0602 - val_loss: 0.0711\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0581 - val_loss: 0.0590\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0564 - val_loss: 0.0612\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0550 - val_loss: 0.0664\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0538 - val_loss: 0.0626\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0528 - val_loss: 0.0641\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0519 - val_loss: 0.0626\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0511 - val_loss: 0.0585\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0506 - val_loss: 0.0537\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0500 - val_loss: 0.0532\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0493 - val_loss: 0.0529\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0489 - val_loss: 0.0510\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0484 - val_loss: 0.0515\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0479 - val_loss: 0.0514\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0477 - val_loss: 0.0595\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0474 - val_loss: 0.0501\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0470 - val_loss: 0.0521\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0466 - val_loss: 0.0578\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0464 - val_loss: 0.0618\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0461 - val_loss: 0.0531\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0459 - val_loss: 0.0568\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0456 - val_loss: 0.0540\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0455 - val_loss: 0.0551\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0453 - val_loss: 0.0559\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0451 - val_loss: 0.0536\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0449 - val_loss: 0.0544\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0448 - val_loss: 0.0502\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0447 - val_loss: 0.0618\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0444 - val_loss: 0.0503\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0443 - val_loss: 0.0543\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0441 - val_loss: 0.0484\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0440 - val_loss: 0.0562\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0439 - val_loss: 0.0494\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0437 - val_loss: 0.0499\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0436 - val_loss: 0.0481\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0435 - val_loss: 0.0533\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0433 - val_loss: 0.0477\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0433 - val_loss: 0.0527\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0432 - val_loss: 0.0527\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0431 - val_loss: 0.0495\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0502\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0459\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0519\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0428 - val_loss: 0.0448\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0455\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0518\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0465\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0423 - val_loss: 0.0549\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0422 - val_loss: 0.0603\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0498\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0565\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0495\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0554\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0420 - val_loss: 0.0518\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0418 - val_loss: 0.0524\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0417 - val_loss: 0.0471\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0417 - val_loss: 0.0723\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0418 - val_loss: 0.0572\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0415 - val_loss: 0.0489\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0414 - val_loss: 0.0501\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0415 - val_loss: 0.0429\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0468\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0461\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0448\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0476\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0482\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0438\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0411 - val_loss: 0.0458\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0411 - val_loss: 0.0451\n",
      "Epoch 76/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0503\n",
      "Epoch 77/1000\n",
      "836/836 - 26s - loss: 0.0409 - val_loss: 0.0490\n",
      "Epoch 78/1000\n",
      "836/836 - 26s - loss: 0.0409 - val_loss: 0.0507\n",
      "Epoch 79/1000\n",
      "836/836 - 26s - loss: 0.0409 - val_loss: 0.0467\n",
      "Epoch 80/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0434\n",
      "Epoch 81/1000\n",
      "836/836 - 26s - loss: 0.0407 - val_loss: 0.0450\n",
      "Epoch 82/1000\n",
      "836/836 - 26s - loss: 0.0406 - val_loss: 0.0509\n",
      "Epoch 83/1000\n",
      "836/836 - 26s - loss: 0.0406 - val_loss: 0.0427\n",
      "Epoch 84/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0444\n",
      "Epoch 85/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0481\n",
      "Epoch 86/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0459\n",
      "Epoch 87/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0499\n",
      "Epoch 88/1000\n",
      "836/836 - 26s - loss: 0.0403 - val_loss: 0.0505\n",
      "Epoch 89/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0577\n",
      "Epoch 90/1000\n",
      "836/836 - 26s - loss: 0.0403 - val_loss: 0.0524\n",
      "Epoch 91/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0450\n",
      "Epoch 92/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0451\n",
      "Epoch 93/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0421\n",
      "Epoch 94/1000\n",
      "836/836 - 26s - loss: 0.0401 - val_loss: 0.0454\n",
      "Epoch 95/1000\n",
      "836/836 - 26s - loss: 0.0401 - val_loss: 0.0467\n",
      "Epoch 96/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0469\n",
      "Epoch 97/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0442\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.2060 - val_loss: 0.1208\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.1041 - val_loss: 0.0890\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0821 - val_loss: 0.0792\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0716 - val_loss: 0.0804\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0654 - val_loss: 0.0735\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0613 - val_loss: 0.0842\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0584 - val_loss: 0.0667\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0562 - val_loss: 0.0668\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0546 - val_loss: 0.0775\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0534 - val_loss: 0.0559\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0524 - val_loss: 0.0622\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0515 - val_loss: 0.0551\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0506 - val_loss: 0.0536\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0500 - val_loss: 0.0541\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0494 - val_loss: 0.0583\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0490 - val_loss: 0.0574\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0484 - val_loss: 0.0646\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0479 - val_loss: 0.0522\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0475 - val_loss: 0.0599\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0471 - val_loss: 0.0584\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0466 - val_loss: 0.0558\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0465 - val_loss: 0.0504\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0461 - val_loss: 0.0514\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0459 - val_loss: 0.0494\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0457 - val_loss: 0.0498\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0453 - val_loss: 0.0481\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0450 - val_loss: 0.0557\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0448 - val_loss: 0.0535\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0446 - val_loss: 0.0529\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0446 - val_loss: 0.0500\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0444 - val_loss: 0.0583\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0440 - val_loss: 0.0521\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0438 - val_loss: 0.0536\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0438 - val_loss: 0.0513\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0435 - val_loss: 0.0509\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0435 - val_loss: 0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0431 - val_loss: 0.0489\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0432 - val_loss: 0.0511\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0430 - val_loss: 0.0501\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0492\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0505\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0537\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0426 - val_loss: 0.0519\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0422 - val_loss: 0.0520\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0467\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0483\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0480\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0419 - val_loss: 0.0589\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0420 - val_loss: 0.0523\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0418 - val_loss: 0.0467\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0416 - val_loss: 0.0481\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0416 - val_loss: 0.0504\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0415 - val_loss: 0.0441\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0452\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0432\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0469\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0480\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0513\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0411 - val_loss: 0.0491\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0518\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0441\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0407 - val_loss: 0.0491\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0452\n",
      "Epoch 64/1000\n",
      "836/836 - 26s - loss: 0.0406 - val_loss: 0.0507\n",
      "Epoch 65/1000\n",
      "836/836 - 26s - loss: 0.0408 - val_loss: 0.0457\n",
      "Epoch 66/1000\n",
      "836/836 - 26s - loss: 0.0403 - val_loss: 0.0452\n",
      "Epoch 67/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0520\n",
      "Epoch 68/1000\n",
      "836/836 - 26s - loss: 0.0406 - val_loss: 0.0463\n",
      "Epoch 69/1000\n",
      "836/836 - 26s - loss: 0.0401 - val_loss: 0.0489\n",
      "Epoch 70/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0497\n",
      "Epoch 71/1000\n",
      "836/836 - 26s - loss: 0.0405 - val_loss: 0.0494\n",
      "Epoch 72/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0465\n",
      "Epoch 73/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0494\n",
      "Epoch 74/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0446\n",
      "Epoch 75/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0476\n",
      "Epoch 76/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0466\n",
      "Epoch 77/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0443\n",
      "Epoch 78/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0446\n",
      "Epoch 79/1000\n",
      "836/836 - 26s - loss: 0.0399 - val_loss: 0.0607\n",
      "Epoch 80/1000\n",
      "836/836 - 26s - loss: 0.0397 - val_loss: 0.0456\n",
      "Epoch 81/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0432\n",
      "Epoch 82/1000\n",
      "836/836 - 26s - loss: 0.0397 - val_loss: 0.0503\n",
      "Epoch 83/1000\n",
      "836/836 - 26s - loss: 0.0395 - val_loss: 0.0455\n",
      "Epoch 1/1000\n",
      "836/836 - 32s - loss: 0.2248 - val_loss: 0.1229\n",
      "Epoch 2/1000\n",
      "836/836 - 26s - loss: 0.1102 - val_loss: 0.0952\n",
      "Epoch 3/1000\n",
      "836/836 - 26s - loss: 0.0897 - val_loss: 0.0817\n",
      "Epoch 4/1000\n",
      "836/836 - 26s - loss: 0.0801 - val_loss: 0.0819\n",
      "Epoch 5/1000\n",
      "836/836 - 26s - loss: 0.0731 - val_loss: 0.0744\n",
      "Epoch 6/1000\n",
      "836/836 - 26s - loss: 0.0683 - val_loss: 0.0650\n",
      "Epoch 7/1000\n",
      "836/836 - 26s - loss: 0.0649 - val_loss: 0.0672\n",
      "Epoch 8/1000\n",
      "836/836 - 26s - loss: 0.0626 - val_loss: 0.0608\n",
      "Epoch 9/1000\n",
      "836/836 - 26s - loss: 0.0601 - val_loss: 0.0641\n",
      "Epoch 10/1000\n",
      "836/836 - 26s - loss: 0.0582 - val_loss: 0.0643\n",
      "Epoch 11/1000\n",
      "836/836 - 26s - loss: 0.0570 - val_loss: 0.0639\n",
      "Epoch 12/1000\n",
      "836/836 - 26s - loss: 0.0554 - val_loss: 0.0557\n",
      "Epoch 13/1000\n",
      "836/836 - 26s - loss: 0.0540 - val_loss: 0.0553\n",
      "Epoch 14/1000\n",
      "836/836 - 26s - loss: 0.0526 - val_loss: 0.0560\n",
      "Epoch 15/1000\n",
      "836/836 - 26s - loss: 0.0517 - val_loss: 0.0533\n",
      "Epoch 16/1000\n",
      "836/836 - 26s - loss: 0.0511 - val_loss: 0.0539\n",
      "Epoch 17/1000\n",
      "836/836 - 26s - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 18/1000\n",
      "836/836 - 26s - loss: 0.0492 - val_loss: 0.0558\n",
      "Epoch 19/1000\n",
      "836/836 - 26s - loss: 0.0487 - val_loss: 0.0520\n",
      "Epoch 20/1000\n",
      "836/836 - 26s - loss: 0.0479 - val_loss: 0.0532\n",
      "Epoch 21/1000\n",
      "836/836 - 26s - loss: 0.0478 - val_loss: 0.0520\n",
      "Epoch 22/1000\n",
      "836/836 - 26s - loss: 0.0469 - val_loss: 0.0474\n",
      "Epoch 23/1000\n",
      "836/836 - 26s - loss: 0.0467 - val_loss: 0.0490\n",
      "Epoch 24/1000\n",
      "836/836 - 26s - loss: 0.0460 - val_loss: 0.0508\n",
      "Epoch 25/1000\n",
      "836/836 - 26s - loss: 0.0458 - val_loss: 0.0540\n",
      "Epoch 26/1000\n",
      "836/836 - 26s - loss: 0.0453 - val_loss: 0.0507\n",
      "Epoch 27/1000\n",
      "836/836 - 26s - loss: 0.0451 - val_loss: 0.0531\n",
      "Epoch 28/1000\n",
      "836/836 - 26s - loss: 0.0446 - val_loss: 0.0551\n",
      "Epoch 29/1000\n",
      "836/836 - 26s - loss: 0.0441 - val_loss: 0.0494\n",
      "Epoch 30/1000\n",
      "836/836 - 26s - loss: 0.0439 - val_loss: 0.0511\n",
      "Epoch 31/1000\n",
      "836/836 - 26s - loss: 0.0440 - val_loss: 0.0497\n",
      "Epoch 32/1000\n",
      "836/836 - 26s - loss: 0.0435 - val_loss: 0.0520\n",
      "Epoch 33/1000\n",
      "836/836 - 26s - loss: 0.0431 - val_loss: 0.0441\n",
      "Epoch 34/1000\n",
      "836/836 - 26s - loss: 0.0430 - val_loss: 0.0519\n",
      "Epoch 35/1000\n",
      "836/836 - 26s - loss: 0.0427 - val_loss: 0.0491\n",
      "Epoch 36/1000\n",
      "836/836 - 26s - loss: 0.0424 - val_loss: 0.0527\n",
      "Epoch 37/1000\n",
      "836/836 - 26s - loss: 0.0429 - val_loss: 0.0518\n",
      "Epoch 38/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0474\n",
      "Epoch 39/1000\n",
      "836/836 - 26s - loss: 0.0419 - val_loss: 0.0468\n",
      "Epoch 40/1000\n",
      "836/836 - 26s - loss: 0.0418 - val_loss: 0.0497\n",
      "Epoch 41/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0529\n",
      "Epoch 42/1000\n",
      "836/836 - 26s - loss: 0.0421 - val_loss: 0.0487\n",
      "Epoch 43/1000\n",
      "836/836 - 26s - loss: 0.0413 - val_loss: 0.0537\n",
      "Epoch 44/1000\n",
      "836/836 - 26s - loss: 0.0412 - val_loss: 0.0446\n",
      "Epoch 45/1000\n",
      "836/836 - 26s - loss: 0.0409 - val_loss: 0.0576\n",
      "Epoch 46/1000\n",
      "836/836 - 26s - loss: 0.0410 - val_loss: 0.0433\n",
      "Epoch 47/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0526\n",
      "Epoch 48/1000\n",
      "836/836 - 26s - loss: 0.0407 - val_loss: 0.0527\n",
      "Epoch 49/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0487\n",
      "Epoch 50/1000\n",
      "836/836 - 26s - loss: 0.0404 - val_loss: 0.0546\n",
      "Epoch 51/1000\n",
      "836/836 - 26s - loss: 0.0402 - val_loss: 0.0492\n",
      "Epoch 52/1000\n",
      "836/836 - 26s - loss: 0.0399 - val_loss: 0.0465\n",
      "Epoch 53/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0450\n",
      "Epoch 54/1000\n",
      "836/836 - 26s - loss: 0.0400 - val_loss: 0.0494\n",
      "Epoch 55/1000\n",
      "836/836 - 26s - loss: 0.0394 - val_loss: 0.0440\n",
      "Epoch 56/1000\n",
      "836/836 - 26s - loss: 0.0398 - val_loss: 0.0493\n",
      "Epoch 57/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0458\n",
      "Epoch 58/1000\n",
      "836/836 - 26s - loss: 0.0392 - val_loss: 0.0631\n",
      "Epoch 59/1000\n",
      "836/836 - 26s - loss: 0.0392 - val_loss: 0.0455\n",
      "Epoch 60/1000\n",
      "836/836 - 26s - loss: 0.0391 - val_loss: 0.0462\n",
      "Epoch 61/1000\n",
      "836/836 - 26s - loss: 0.0391 - val_loss: 0.0463\n",
      "Epoch 62/1000\n",
      "836/836 - 26s - loss: 0.0393 - val_loss: 0.0455\n",
      "Epoch 63/1000\n",
      "836/836 - 26s - loss: 0.0390 - val_loss: 0.0512\n",
      "Epoch 1/1000\n",
      "836/836 - 40s - loss: 0.2393 - val_loss: 0.1327\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.1024 - val_loss: 0.0879\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0824 - val_loss: 0.0836\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0729 - val_loss: 0.0751\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0658 - val_loss: 0.0722\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0604 - val_loss: 0.0640\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0559 - val_loss: 0.0520\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0534 - val_loss: 0.0527\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0482 - val_loss: 0.0543\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0463 - val_loss: 0.0549\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0449 - val_loss: 0.0448\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0438 - val_loss: 0.0459\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0422 - val_loss: 0.0480\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0408 - val_loss: 0.0546\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0432\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0395 - val_loss: 0.0522\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0385 - val_loss: 0.0574\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0376 - val_loss: 0.0458\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0369 - val_loss: 0.0393\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0364 - val_loss: 0.0369\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0357 - val_loss: 0.0439\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0348 - val_loss: 0.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0342 - val_loss: 0.0391\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0339 - val_loss: 0.0394\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0327 - val_loss: 0.0399\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0437\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0475\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0316 - val_loss: 0.0341\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0311 - val_loss: 0.0378\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0309 - val_loss: 0.0374\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0357\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0302 - val_loss: 0.0395\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0298 - val_loss: 0.0362\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0294 - val_loss: 0.0642\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0288 - val_loss: 0.0326\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0287 - val_loss: 0.0336\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0287 - val_loss: 0.0358\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0282 - val_loss: 0.0331\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0276 - val_loss: 0.0384\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0275 - val_loss: 0.0295\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0445\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0320\n",
      "Epoch 44/1000\n",
      "836/836 - 25s - loss: 0.0270 - val_loss: 0.0300\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0267 - val_loss: 0.0600\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0264 - val_loss: 0.0303\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0266 - val_loss: 0.0288\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0261 - val_loss: 0.0289\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0257 - val_loss: 0.0280\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0256 - val_loss: 0.0373\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0259 - val_loss: 0.0279\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0255 - val_loss: 0.0299\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0252 - val_loss: 0.0313\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0252 - val_loss: 0.0278\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0251 - val_loss: 0.0337\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0248 - val_loss: 0.0241\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0247 - val_loss: 0.0296\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0246 - val_loss: 0.0257\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0247 - val_loss: 0.0267\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0242 - val_loss: 0.0323\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0243 - val_loss: 0.0300\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0245 - val_loss: 0.0296\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0240 - val_loss: 0.0266\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0241 - val_loss: 0.0305\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0243 - val_loss: 0.0280\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0237 - val_loss: 0.0306\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0236 - val_loss: 0.0279\n",
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0234 - val_loss: 0.0264\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0231 - val_loss: 0.0388\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0234 - val_loss: 0.0259\n",
      "Epoch 71/1000\n",
      "836/836 - 25s - loss: 0.0236 - val_loss: 0.0341\n",
      "Epoch 72/1000\n",
      "836/836 - 25s - loss: 0.0231 - val_loss: 0.0242\n",
      "Epoch 73/1000\n",
      "836/836 - 25s - loss: 0.0231 - val_loss: 0.0250\n",
      "Epoch 74/1000\n",
      "836/836 - 25s - loss: 0.0229 - val_loss: 0.0278\n",
      "Epoch 75/1000\n",
      "836/836 - 25s - loss: 0.0227 - val_loss: 0.0243\n",
      "Epoch 76/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0303\n",
      "Epoch 77/1000\n",
      "836/836 - 25s - loss: 0.0228 - val_loss: 0.0253\n",
      "Epoch 78/1000\n",
      "836/836 - 25s - loss: 0.0226 - val_loss: 0.0237\n",
      "Epoch 79/1000\n",
      "836/836 - 25s - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 80/1000\n",
      "836/836 - 25s - loss: 0.0221 - val_loss: 0.0290\n",
      "Epoch 81/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0287\n",
      "Epoch 82/1000\n",
      "836/836 - 25s - loss: 0.0219 - val_loss: 0.0212\n",
      "Epoch 83/1000\n",
      "836/836 - 25s - loss: 0.0225 - val_loss: 0.0243\n",
      "Epoch 84/1000\n",
      "836/836 - 25s - loss: 0.0220 - val_loss: 0.0257\n",
      "Epoch 85/1000\n",
      "836/836 - 25s - loss: 0.0219 - val_loss: 0.0301\n",
      "Epoch 86/1000\n",
      "836/836 - 25s - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 87/1000\n",
      "836/836 - 25s - loss: 0.0220 - val_loss: 0.0267\n",
      "Epoch 88/1000\n",
      "836/836 - 25s - loss: 0.0216 - val_loss: 0.0220\n",
      "Epoch 89/1000\n",
      "836/836 - 25s - loss: 0.0223 - val_loss: 0.0284\n",
      "Epoch 90/1000\n",
      "836/836 - 25s - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 91/1000\n",
      "836/836 - 25s - loss: 0.0218 - val_loss: 0.0309\n",
      "Epoch 92/1000\n",
      "836/836 - 25s - loss: 0.0212 - val_loss: 0.0277\n",
      "Epoch 93/1000\n",
      "836/836 - 25s - loss: 0.0218 - val_loss: 0.0235\n",
      "Epoch 94/1000\n",
      "836/836 - 25s - loss: 0.0213 - val_loss: 0.0247\n",
      "Epoch 95/1000\n",
      "836/836 - 25s - loss: 0.0215 - val_loss: 0.0247\n",
      "Epoch 96/1000\n",
      "836/836 - 25s - loss: 0.0212 - val_loss: 0.0234\n",
      "Epoch 97/1000\n",
      "836/836 - 25s - loss: 0.0216 - val_loss: 0.0223\n",
      "Epoch 98/1000\n",
      "836/836 - 25s - loss: 0.0212 - val_loss: 0.0262\n",
      "Epoch 99/1000\n",
      "836/836 - 25s - loss: 0.0210 - val_loss: 0.0313\n",
      "Epoch 100/1000\n",
      "836/836 - 25s - loss: 0.0208 - val_loss: 0.0258\n",
      "Epoch 101/1000\n",
      "836/836 - 25s - loss: 0.0210 - val_loss: 0.0290\n",
      "Epoch 102/1000\n",
      "836/836 - 25s - loss: 0.0206 - val_loss: 0.0233\n",
      "Epoch 103/1000\n",
      "836/836 - 25s - loss: 0.0209 - val_loss: 0.0230\n",
      "Epoch 104/1000\n",
      "836/836 - 25s - loss: 0.0208 - val_loss: 0.0251\n",
      "Epoch 105/1000\n",
      "836/836 - 25s - loss: 0.0209 - val_loss: 0.0243\n",
      "Epoch 106/1000\n",
      "836/836 - 25s - loss: 0.0211 - val_loss: 0.0228\n",
      "Epoch 107/1000\n",
      "836/836 - 25s - loss: 0.0206 - val_loss: 0.0272\n",
      "Epoch 108/1000\n",
      "836/836 - 25s - loss: 0.0206 - val_loss: 0.0223\n",
      "Epoch 109/1000\n",
      "836/836 - 25s - loss: 0.0207 - val_loss: 0.0275\n",
      "Epoch 110/1000\n",
      "836/836 - 25s - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 111/1000\n",
      "836/836 - 25s - loss: 0.0206 - val_loss: 0.0210\n",
      "Epoch 112/1000\n",
      "836/836 - 25s - loss: 0.0207 - val_loss: 0.0228\n",
      "Epoch 1/1000\n",
      "836/836 - 30s - loss: 0.2823 - val_loss: 0.1401\n",
      "Epoch 2/1000\n",
      "836/836 - 25s - loss: 0.1216 - val_loss: 0.1005\n",
      "Epoch 3/1000\n",
      "836/836 - 25s - loss: 0.0978 - val_loss: 0.0898\n",
      "Epoch 4/1000\n",
      "836/836 - 25s - loss: 0.0831 - val_loss: 0.0719\n",
      "Epoch 5/1000\n",
      "836/836 - 25s - loss: 0.0752 - val_loss: 0.0681\n",
      "Epoch 6/1000\n",
      "836/836 - 25s - loss: 0.0681 - val_loss: 0.0733\n",
      "Epoch 7/1000\n",
      "836/836 - 25s - loss: 0.0638 - val_loss: 0.0595\n",
      "Epoch 8/1000\n",
      "836/836 - 25s - loss: 0.0603 - val_loss: 0.0586\n",
      "Epoch 9/1000\n",
      "836/836 - 25s - loss: 0.0576 - val_loss: 0.0799\n",
      "Epoch 10/1000\n",
      "836/836 - 25s - loss: 0.0550 - val_loss: 0.0587\n",
      "Epoch 11/1000\n",
      "836/836 - 25s - loss: 0.0531 - val_loss: 0.0511\n",
      "Epoch 12/1000\n",
      "836/836 - 25s - loss: 0.0510 - val_loss: 0.0562\n",
      "Epoch 13/1000\n",
      "836/836 - 25s - loss: 0.0497 - val_loss: 0.0545\n",
      "Epoch 14/1000\n",
      "836/836 - 25s - loss: 0.0484 - val_loss: 0.0559\n",
      "Epoch 15/1000\n",
      "836/836 - 25s - loss: 0.0476 - val_loss: 0.0455\n",
      "Epoch 16/1000\n",
      "836/836 - 25s - loss: 0.0464 - val_loss: 0.0440\n",
      "Epoch 17/1000\n",
      "836/836 - 25s - loss: 0.0454 - val_loss: 0.0503\n",
      "Epoch 18/1000\n",
      "836/836 - 25s - loss: 0.0444 - val_loss: 0.0453\n",
      "Epoch 19/1000\n",
      "836/836 - 25s - loss: 0.0442 - val_loss: 0.0597\n",
      "Epoch 20/1000\n",
      "836/836 - 25s - loss: 0.0428 - val_loss: 0.0453\n",
      "Epoch 21/1000\n",
      "836/836 - 25s - loss: 0.0424 - val_loss: 0.0468\n",
      "Epoch 22/1000\n",
      "836/836 - 25s - loss: 0.0417 - val_loss: 0.0450\n",
      "Epoch 23/1000\n",
      "836/836 - 25s - loss: 0.0412 - val_loss: 0.0427\n",
      "Epoch 24/1000\n",
      "836/836 - 25s - loss: 0.0411 - val_loss: 0.0425\n",
      "Epoch 25/1000\n",
      "836/836 - 25s - loss: 0.0400 - val_loss: 0.0384\n",
      "Epoch 26/1000\n",
      "836/836 - 25s - loss: 0.0397 - val_loss: 0.0534\n",
      "Epoch 27/1000\n",
      "836/836 - 25s - loss: 0.0395 - val_loss: 0.0409\n",
      "Epoch 28/1000\n",
      "836/836 - 25s - loss: 0.0391 - val_loss: 0.0374\n",
      "Epoch 29/1000\n",
      "836/836 - 25s - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 30/1000\n",
      "836/836 - 25s - loss: 0.0378 - val_loss: 0.0464\n",
      "Epoch 31/1000\n",
      "836/836 - 25s - loss: 0.0380 - val_loss: 0.0434\n",
      "Epoch 32/1000\n",
      "836/836 - 25s - loss: 0.0375 - val_loss: 0.0353\n",
      "Epoch 33/1000\n",
      "836/836 - 25s - loss: 0.0369 - val_loss: 0.0525\n",
      "Epoch 34/1000\n",
      "836/836 - 25s - loss: 0.0366 - val_loss: 0.0821\n",
      "Epoch 35/1000\n",
      "836/836 - 25s - loss: 0.0388 - val_loss: 0.0457\n",
      "Epoch 36/1000\n",
      "836/836 - 25s - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 37/1000\n",
      "836/836 - 25s - loss: 0.0358 - val_loss: 0.0364\n",
      "Epoch 38/1000\n",
      "836/836 - 25s - loss: 0.0355 - val_loss: 0.0365\n",
      "Epoch 39/1000\n",
      "836/836 - 25s - loss: 0.0347 - val_loss: 0.0460\n",
      "Epoch 40/1000\n",
      "836/836 - 25s - loss: 0.0352 - val_loss: 0.0357\n",
      "Epoch 41/1000\n",
      "836/836 - 25s - loss: 0.0344 - val_loss: 0.0326\n",
      "Epoch 42/1000\n",
      "836/836 - 25s - loss: 0.0343 - val_loss: 0.0362\n",
      "Epoch 43/1000\n",
      "836/836 - 25s - loss: 0.0340 - val_loss: 0.0483\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 - 25s - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 45/1000\n",
      "836/836 - 25s - loss: 0.0338 - val_loss: 0.0446\n",
      "Epoch 46/1000\n",
      "836/836 - 25s - loss: 0.0337 - val_loss: 0.0372\n",
      "Epoch 47/1000\n",
      "836/836 - 25s - loss: 0.0333 - val_loss: 0.0346\n",
      "Epoch 48/1000\n",
      "836/836 - 25s - loss: 0.0328 - val_loss: 0.0338\n",
      "Epoch 49/1000\n",
      "836/836 - 25s - loss: 0.0332 - val_loss: 0.0364\n",
      "Epoch 50/1000\n",
      "836/836 - 25s - loss: 0.0331 - val_loss: 0.0313\n",
      "Epoch 51/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0324\n",
      "Epoch 52/1000\n",
      "836/836 - 25s - loss: 0.0329 - val_loss: 0.0372\n",
      "Epoch 53/1000\n",
      "836/836 - 25s - loss: 0.0321 - val_loss: 0.0368\n",
      "Epoch 54/1000\n",
      "836/836 - 25s - loss: 0.0326 - val_loss: 0.0349\n",
      "Epoch 55/1000\n",
      "836/836 - 25s - loss: 0.0320 - val_loss: 0.0312\n",
      "Epoch 56/1000\n",
      "836/836 - 25s - loss: 0.0323 - val_loss: 0.0346\n",
      "Epoch 57/1000\n",
      "836/836 - 25s - loss: 0.0316 - val_loss: 0.0330\n",
      "Epoch 58/1000\n",
      "836/836 - 25s - loss: 0.0315 - val_loss: 0.0376\n",
      "Epoch 59/1000\n",
      "836/836 - 25s - loss: 0.0316 - val_loss: 0.0310\n",
      "Epoch 60/1000\n",
      "836/836 - 25s - loss: 0.0317 - val_loss: 0.0312\n",
      "Epoch 61/1000\n",
      "836/836 - 25s - loss: 0.0314 - val_loss: 0.0302\n",
      "Epoch 62/1000\n",
      "836/836 - 25s - loss: 0.0312 - val_loss: 0.0362\n",
      "Epoch 63/1000\n",
      "836/836 - 25s - loss: 0.0311 - val_loss: 0.0354\n",
      "Epoch 64/1000\n",
      "836/836 - 25s - loss: 0.0309 - val_loss: 0.0310\n",
      "Epoch 65/1000\n",
      "836/836 - 25s - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 66/1000\n",
      "836/836 - 25s - loss: 0.0306 - val_loss: 0.0294\n",
      "Epoch 67/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0404\n",
      "Epoch 68/1000\n",
      "836/836 - 25s - loss: 0.0306 - val_loss: 0.0295\n",
      "Epoch 69/1000\n",
      "836/836 - 25s - loss: 0.0301 - val_loss: 0.0291\n",
      "Epoch 70/1000\n",
      "836/836 - 25s - loss: 0.0307 - val_loss: 0.0307\n",
      "Epoch 71/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0295\n",
      "Epoch 72/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0458\n",
      "Epoch 73/1000\n",
      "836/836 - 25s - loss: 0.0304 - val_loss: 0.0292\n",
      "Epoch 74/1000\n",
      "836/836 - 25s - loss: 0.0298 - val_loss: 0.0291\n",
      "Epoch 75/1000\n",
      "836/836 - 25s - loss: 0.0296 - val_loss: 0.0368\n",
      "Epoch 76/1000\n",
      "836/836 - 25s - loss: 0.0303 - val_loss: 0.0293\n",
      "Epoch 77/1000\n",
      "836/836 - 25s - loss: 0.0300 - val_loss: 0.0336\n",
      "Epoch 78/1000\n",
      "836/836 - 25s - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 79/1000\n",
      "836/836 - 25s - loss: 0.0294 - val_loss: 0.0284\n",
      "Epoch 80/1000\n",
      "836/836 - 25s - loss: 0.0296 - val_loss: 0.0480\n",
      "Epoch 81/1000\n",
      "836/836 - 25s - loss: 0.0322 - val_loss: 0.0294\n",
      "Epoch 82/1000\n",
      "836/836 - 25s - loss: 0.0291 - val_loss: 0.0302\n",
      "Epoch 83/1000\n",
      "836/836 - 25s - loss: 0.0293 - val_loss: 0.0362\n",
      "Epoch 84/1000\n",
      "836/836 - 25s - loss: 0.0294 - val_loss: 0.0282\n",
      "Epoch 85/1000\n",
      "836/836 - 25s - loss: 0.0294 - val_loss: 0.0292\n",
      "Epoch 86/1000\n",
      "836/836 - 25s - loss: 0.0292 - val_loss: 0.0435\n",
      "Epoch 87/1000\n",
      "836/836 - 25s - loss: 0.0289 - val_loss: 0.0294\n",
      "Epoch 88/1000\n",
      "836/836 - 25s - loss: 0.0290 - val_loss: 0.0283\n",
      "Epoch 89/1000\n",
      "836/836 - 25s - loss: 0.0293 - val_loss: 0.0293\n",
      "Epoch 90/1000\n",
      "836/836 - 25s - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 91/1000\n",
      "836/836 - 25s - loss: 0.0288 - val_loss: 0.0356\n",
      "Epoch 92/1000\n",
      "836/836 - 25s - loss: 0.0289 - val_loss: 0.0331\n",
      "Epoch 93/1000\n",
      "836/836 - 25s - loss: 0.0284 - val_loss: 0.0288\n",
      "Epoch 94/1000\n",
      "836/836 - 25s - loss: 0.0286 - val_loss: 0.0297\n",
      "Epoch 95/1000\n",
      "836/836 - 25s - loss: 0.0289 - val_loss: 0.0296\n",
      "Epoch 96/1000\n",
      "836/836 - 25s - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 97/1000\n",
      "836/836 - 25s - loss: 0.0286 - val_loss: 0.0295\n",
      "Epoch 98/1000\n",
      "836/836 - 25s - loss: 0.0287 - val_loss: 0.0309\n",
      "Epoch 99/1000\n",
      "836/836 - 25s - loss: 0.0285 - val_loss: 0.0295\n",
      "Epoch 100/1000\n",
      "836/836 - 25s - loss: 0.0284 - val_loss: 0.0302\n",
      "Epoch 101/1000\n",
      "836/836 - 25s - loss: 0.0283 - val_loss: 0.0284\n",
      "Epoch 102/1000\n",
      "836/836 - 25s - loss: 0.0280 - val_loss: 0.0259\n",
      "Epoch 103/1000\n",
      "836/836 - 25s - loss: 0.0282 - val_loss: 0.0328\n",
      "Epoch 104/1000\n",
      "836/836 - 25s - loss: 0.0284 - val_loss: 0.0304\n",
      "Epoch 105/1000\n",
      "836/836 - 25s - loss: 0.0283 - val_loss: 0.0285\n",
      "Epoch 106/1000\n",
      "836/836 - 25s - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 107/1000\n",
      "836/836 - 25s - loss: 0.0279 - val_loss: 0.0293\n",
      "Epoch 108/1000\n",
      "836/836 - 25s - loss: 0.0280 - val_loss: 0.0345\n",
      "Epoch 109/1000\n",
      "836/836 - 25s - loss: 0.0280 - val_loss: 0.0326\n",
      "Epoch 110/1000\n",
      "836/836 - 25s - loss: 0.0281 - val_loss: 0.0307\n",
      "Epoch 111/1000\n",
      "836/836 - 25s - loss: 0.0276 - val_loss: 0.0382\n",
      "Epoch 112/1000\n",
      "836/836 - 25s - loss: 0.0279 - val_loss: 0.0314\n",
      "Epoch 113/1000\n",
      "836/836 - 25s - loss: 0.0277 - val_loss: 0.0365\n",
      "Epoch 114/1000\n",
      "836/836 - 25s - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 115/1000\n",
      "836/836 - 25s - loss: 0.0279 - val_loss: 0.0281\n",
      "Epoch 116/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0290\n",
      "Epoch 117/1000\n",
      "836/836 - 25s - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 118/1000\n",
      "836/836 - 25s - loss: 0.0278 - val_loss: 0.0613\n",
      "Epoch 119/1000\n",
      "836/836 - 25s - loss: 0.0279 - val_loss: 0.0302\n",
      "Epoch 120/1000\n",
      "836/836 - 25s - loss: 0.0275 - val_loss: 0.0290\n",
      "Epoch 121/1000\n",
      "836/836 - 25s - loss: 0.0277 - val_loss: 0.0293\n",
      "Epoch 122/1000\n",
      "836/836 - 25s - loss: 0.0272 - val_loss: 0.0296\n",
      "Epoch 123/1000\n",
      "836/836 - 25s - loss: 0.0274 - val_loss: 0.0294\n",
      "Epoch 124/1000\n",
      "836/836 - 25s - loss: 0.0271 - val_loss: 0.0277\n",
      "Epoch 125/1000\n",
      "836/836 - 25s - loss: 0.0274 - val_loss: 0.0285\n",
      "Epoch 126/1000\n",
      "836/836 - 25s - loss: 0.0282 - val_loss: 0.0307\n",
      "Epoch 127/1000\n",
      "836/836 - 25s - loss: 0.0269 - val_loss: 0.0254\n",
      "Epoch 128/1000\n",
      "836/836 - 25s - loss: 0.0267 - val_loss: 0.0281\n",
      "Epoch 129/1000\n",
      "836/836 - 25s - loss: 0.0274 - val_loss: 0.0278\n",
      "Epoch 130/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0352\n",
      "Epoch 131/1000\n",
      "836/836 - 25s - loss: 0.0273 - val_loss: 0.0300\n",
      "Epoch 132/1000\n",
      "836/836 - 25s - loss: 0.0265 - val_loss: 0.0263\n"
     ]
    }
   ],
   "source": [
    "depth = [5,10,15,20,30,40,50,60,70,80,90,100,125,150,175,200,225,250,275,300,350,400,\n",
    "              500,600,700,800,900,1000,1100,1300,1500,1750,2000]\n",
    "# 训练30 - 1000m\n",
    "for i in range(0,33):\n",
    "    train_model_CNN(x_train,y_train[:,i:i+1],x_val,y_val[:,i:i+1],\n",
    "                'D:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/sali/model2/CNN_sali_'+str(depth[i])+'m.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c42d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T06:31:42.566183Z",
     "start_time": "2023-12-30T06:31:42.566183Z"
    }
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d8c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.656441Z",
     "start_time": "2024-06-10T10:14:19.656441Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = create_model(128,256)\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# checkpoint_path='./CNN_model_16.h5'\n",
    "# keras_callbacks   = [\n",
    "#       EarlyStopping(monitor='val_loss', patience=30, mode='min', min_delta=0.001),\n",
    "#       ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398477b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.659436Z",
     "start_time": "2024-06-10T10:14:19.659436Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_epochs = 1000\n",
    "# batch_size = 10240\n",
    "\n",
    "# history = model.fit(x_train, y_train[:,14:15], validation_data=(x_val,y_val[:,14:15]),\n",
    "#                     epochs=num_epochs, batch_size=batch_size, verbose=2, callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275d7a0",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7d0b3be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T01:18:09.160613Z",
     "start_time": "2024-06-13T01:18:09.151627Z"
    },
    "code_folding": [
     3,
     16,
     45
    ]
   },
   "outputs": [],
   "source": [
    "# 评估函数定义\n",
    "# 异常相关系数\n",
    "import math\n",
    "def acc(actual, predicted):\n",
    "    pred_avg = np.average(predicted)\n",
    "\n",
    "    act_avg = np.average(actual)\n",
    "    diff_pred = predicted - pred_avg\n",
    "    diff_act = actual - act_avg\n",
    "    numerator = np.mean(np.sum(diff_pred*diff_act, axis=0))\n",
    "    denominator = math.sqrt(np.mean(np.sum(diff_pred**2, axis=0)) * np.mean(np.sum(diff_act**2, axis=0)))\n",
    "    ret_val = numerator/denominator\n",
    "    return (100 * ret_val)\n",
    "\n",
    "\n",
    "# 查看损失\n",
    "def look_loss(history):\n",
    "    plt.figure(figsize=(6.3, 2.5), dpi = 100)\n",
    "    plt.plot(history.history['loss'], label='training data')\n",
    "    plt.plot(history.history['val_loss'], label='validation data')\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 模型预测\n",
    "def all_estimate(best_model,x_test,y_test):\n",
    "    testPred_1 = best_model.predict(x_test)\n",
    "    a = y_test\n",
    "    y_test_p = a.reshape(-1,1)\n",
    "    testPred_p = testPred_1.reshape(-1,1)\n",
    "\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(y_test_p,testPred_p))\n",
    "    #print('Test RMSE: %.3f' % rmse)\n",
    "    #print('%.3f' % rmse)\n",
    "\n",
    "   # print('acc:',acc(y_test_p,testPred_p))\n",
    "\n",
    "    r2 = r2_score(y_test_p,testPred_p)\n",
    "    #print(\"R² score: %.4f\" % r2)  \n",
    "    print(\"%.4f\"% r2)  \n",
    "    \n",
    "\n",
    "def respective_estimate(best_model,x_test,y_test):\n",
    "    re2_list = []\n",
    "    rmse_list = []\n",
    "    for i in range(6):\n",
    "        # 模型预测\n",
    "        testPred = best_model.predict(x_test[i:i+1])\n",
    "        a = y_test[i:i+1]\n",
    "        y_test_p = a.reshape(-1,1)\n",
    "        testPred_p = testPred.reshape(-1,1)\n",
    "        r2 = r2_score(y_test_p,testPred_p)\n",
    "        rmse = sqrt(mean_squared_error(y_test_p,testPred_p))\n",
    "        re2_list.append(r2)\n",
    "        rmse_list.append(rmse)    \n",
    "    return re2_list,rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2f202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.666501Z",
     "start_time": "2024-06-10T10:14:19.666501Z"
    }
   },
   "outputs": [],
   "source": [
    "#look_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2126b3",
   "metadata": {},
   "source": [
    "### 对指定层进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0c3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.670426Z",
     "start_time": "2024-06-10T10:14:19.670426Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6afc7fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:34:41.184984Z",
     "start_time": "2024-06-10T10:34:02.677843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model('D:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/sali/model2/CNN_sali_5m.h5')\n",
    "all_estimate(best_model,x_test,y_test[:,0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b383d",
   "metadata": {},
   "source": [
    "### 对所有层进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9bf805b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T01:28:22.057997Z",
     "start_time": "2024-06-13T01:18:47.272029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943\n",
      "0.9924\n",
      "0.9913\n",
      "0.9910\n",
      "0.9868\n",
      "0.9808\n",
      "0.9719\n",
      "0.9681\n",
      "0.9666\n",
      "0.9643\n",
      "0.9648\n",
      "0.9567\n",
      "0.9449\n",
      "0.9433\n",
      "0.9297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m  best_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/sali/model2/CNN_sali_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(depth[i])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(str(depth[i])+'m 测试集：')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m  \u001b[43mall_estimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[96], line 31\u001b[0m, in \u001b[0;36mall_estimate\u001b[1;34m(best_model, x_test, y_test)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_estimate\u001b[39m(best_model,x_test,y_test):\n\u001b[1;32m---> 31\u001b[0m     testPred_1 \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     a \u001b[38;5;241m=\u001b[39m y_test\n\u001b[0;32m     33\u001b[0m     y_test_p \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1629\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1628\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1629\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1630\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1631\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:862\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    860\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\tools\\Anaconda\\envs\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "for i in range(0,33):\n",
    "    best_model = tf.keras.models.load_model('D:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/sali/model2/CNN_sali_'+str(depth[i])+'m.h5')\n",
    "   # print(str(depth[i])+'m 测试集：')\n",
    "    all_estimate(best_model,x_test,y_test[:,i:i+1])\n",
    "# re2_list,rmse_list = respective_estimate(best_model,x_test,y_test[:,:,:,:,0:5])\n",
    "# re2_list,rmse_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b29cb",
   "metadata": {},
   "source": [
    "# 保存预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf59029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.674412Z",
     "start_time": "2024-06-10T10:14:19.674412Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "result = [] \n",
    "for i in range(0,33):\n",
    "    best_model = tf.keras.models.load_model('D:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/temp/model1/CNN_temp_'+str(depth[i])+'m.h5')\n",
    "    #print('预测第'+str(depth[i]+'m的温度')\n",
    "    testPred = best_model.predict(x_test)\n",
    "    result.append(testPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d025e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.675411Z",
     "start_time": "2024-06-10T10:14:19.675411Z"
    }
   },
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "print(result.shape)\n",
    "result = np.transpose(result,(1,2,0))\n",
    "print(result.shape)\n",
    "result = result.reshape(-1,33)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27529e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.676409Z",
     "start_time": "2024-06-10T10:14:19.676409Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.save(\"model/CNN/result/result_CNN_CBAM_30_1000m.npy\",result)\n",
    "# result= np.load(\"model/CNN/result/result_CNN_CBAM_30_1000m.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbce78",
   "metadata": {},
   "source": [
    "## 对预测结果进行反归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f0e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.677407Z",
     "start_time": "2024-06-10T10:14:19.677407Z"
    }
   },
   "outputs": [],
   "source": [
    "#y_test = y_test.reshape(-1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f64c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.677407Z",
     "start_time": "2024-06-10T10:14:19.677407Z"
    }
   },
   "outputs": [],
   "source": [
    "result.shape,y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c1c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.678406Z",
     "start_time": "2024-06-10T10:14:19.678406Z"
    }
   },
   "outputs": [],
   "source": [
    "result_unscaled = scaler_l.inverse_transform(result)\n",
    "y_test_unscaled = scaler_l.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fde36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.679404Z",
     "start_time": "2024-06-10T10:14:19.679404Z"
    }
   },
   "outputs": [],
   "source": [
    "result_unscaled.shape,y_test_unscaled.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b42fb",
   "metadata": {},
   "source": [
    "## 评估反归一化之后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8346d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.680403Z",
     "start_time": "2024-06-10T10:14:19.680403Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,33):\n",
    "    r2 = r2_score(y_test_unscaled[:,i],result_unscaled[:,i])\n",
    "    print(str(depth[i])+'m R² score:',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8c8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.681401Z",
     "start_time": "2024-06-10T10:14:19.681401Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,33):\n",
    "    mse =  mean_squared_error(y_test_unscaled[:,i],result_unscaled[:,i])\n",
    "    print(str(depth[i])+'m Test mse: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa065c9",
   "metadata": {},
   "source": [
    "# 预测结果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b57477",
   "metadata": {},
   "source": [
    "## 为归一化之后的预测值和真实值填充nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20a38d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.682399Z",
     "start_time": "2024-06-10T10:14:19.682399Z"
    }
   },
   "outputs": [],
   "source": [
    "len(nan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ff7a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.683398Z",
     "start_time": "2024-06-10T10:14:19.683398Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_data_ss_depth_test = np.transpose(cat_data_ss_depth,(1,2,0,3))\n",
    "# print(cat_data_ss_depth_test.shape)\n",
    "# cat_data_ss_depth_test = cat_data_ss_depth_test.reshape ((-1,132*20))\n",
    "# print(cat_data_ss_depth_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2458bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.684396Z",
     "start_time": "2024-06-10T10:14:19.684396Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_data_ss_depth_test[cat_data_ss_depth_test == 32767] = np.nan\n",
    "# print('cat_data_ss_depth_test删除nan值之前',cat_data_ss_depth_test.shape)\n",
    "# # 使用 numpy.isnan 函数检测NaN值\n",
    "# nan_mask = np.isnan(cat_data_ss_depth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ee998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.684396Z",
     "start_time": "2024-06-10T10:14:19.684396Z"
    }
   },
   "outputs": [],
   "source": [
    "# nan_mask[nan_mask.any(axis=1) == True] = True   # nan为True,只要有一个通道存在nan,就都设置为nan\n",
    "# nan_masks = nan_mask[:,1]    #得到图像的masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129cf08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.685395Z",
     "start_time": "2024-06-10T10:14:19.685395Z"
    }
   },
   "outputs": [],
   "source": [
    "### 创建一个形状与nan_masks相同且全是nan的数组\n",
    "testPred_with_nan = np.full((161024,12*33), np.nan)  \n",
    "print(testPred_with_nan.shape)\n",
    "\n",
    "y_test_with_nan = np.full((161024,12*33), np.nan)  \n",
    "print(y_test_with_nan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505873d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.686393Z",
     "start_time": "2024-06-10T10:14:19.686393Z"
    }
   },
   "outputs": [],
   "source": [
    "result_unscaled_reshape = result_unscaled.reshape(12,-1,33)\n",
    "print(result_unscaled_reshape.shape)\n",
    "result_unscaled_reshape = np.transpose(result_unscaled_reshape,(1,0,2))\n",
    "print(result_unscaled_reshape.shape)\n",
    "result_unscaled_reshape = result_unscaled_reshape.reshape(-1,12*33)\n",
    "print(result_unscaled_reshape.shape)\n",
    "\n",
    "# ==================================================================== #\n",
    "\n",
    "y_test_unscaled_reshape = y_test_unscaled.reshape(12,-1,33)\n",
    "print(y_test_unscaled_reshape.shape)\n",
    "y_test_unscaled_reshape = np.transpose(y_test_unscaled_reshape,(1,0,2))\n",
    "print(y_test_unscaled_reshape.shape)\n",
    "y_test_unscaled_reshape = y_test_unscaled_reshape.reshape(-1,12*33)\n",
    "print(y_test_unscaled_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c685d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.687391Z",
     "start_time": "2024-06-10T10:14:19.687391Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_unscaled.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a971489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.688390Z",
     "start_time": "2024-06-10T10:14:19.688390Z"
    }
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "for i,nanmask in enumerate(nan_mask):   # i从0开始\n",
    "\n",
    "    if (nanmask ==True): # True 代表没有nan，使用预测值进行填充\n",
    "        testPred_with_nan[i] = result_unscaled_reshape[num]\n",
    "        y_test_with_nan[i] = y_test_unscaled_reshape[num]\n",
    "        num = num + 1\n",
    "        \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4185c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.690387Z",
     "start_time": "2024-06-10T10:14:19.690387Z"
    }
   },
   "outputs": [],
   "source": [
    "testPred_with_nan = testPred_with_nan.reshape(272, 592,12,33)\n",
    "testPred_with_nan = np.transpose(testPred_with_nan,(2,3,0,1))\n",
    "\n",
    "\n",
    "y_test_with_nan = y_test_with_nan.reshape(272, 592,12,33)\n",
    "y_test_with_nan = np.transpose(y_test_with_nan,(2,3,0,1))\n",
    "\n",
    "print(testPred_with_nan.shape,y_test_with_nan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfa8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T13:07:37.341964Z",
     "start_time": "2023-10-06T13:07:37.302028Z"
    }
   },
   "source": [
    "# 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347081c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.694409Z",
     "start_time": "2024-06-10T10:14:19.694409Z"
    }
   },
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cb507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.697397Z",
     "start_time": "2024-06-10T10:14:19.697397Z"
    }
   },
   "outputs": [],
   "source": [
    "lon.append(data_ssh['lon'][4:-4].data)\n",
    "lat.append(data_ssh['lat'][4:-4].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478dda8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.700380Z",
     "start_time": "2024-06-10T10:14:19.700380Z"
    }
   },
   "outputs": [],
   "source": [
    "len(lat),len(lat[0]),len(lon),len(lon[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a8f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.703383Z",
     "start_time": "2024-06-10T10:14:19.703383Z"
    }
   },
   "outputs": [],
   "source": [
    "start_year = 2015\n",
    "end_year =2015\n",
    "time = []\n",
    "date_range = pd.date_range(datetime(start_year,1,1),datetime(end_year+1,1,1),freq='1M')\n",
    "len(date_range)\n",
    "for i in range(len(date_range)):\n",
    "    time.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f5fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.704364Z",
     "start_time": "2024-06-10T10:14:19.704364Z"
    }
   },
   "outputs": [],
   "source": [
    "time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a1771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.705363Z",
     "start_time": "2024-06-10T10:14:19.705363Z"
    }
   },
   "outputs": [],
   "source": [
    "# new_NC.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4751334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.706361Z",
     "start_time": "2024-06-10T10:14:19.706361Z"
    }
   },
   "outputs": [],
   "source": [
    "new_NC = nc.Dataset(\"D:/codeFile/jupyterDemo/3d_ts/BPNN/model/new_0-2000m_24.6.6/CNN/temp/result/model1/result5_2000m_CNN_CBAM.nc\",\n",
    "                    'w', format='NETCDF4')\n",
    "\n",
    "'''\n",
    "定义维度，后一个参数表示维度的长度，因为是合并的同一个产品的数据，所以是统一\n",
    "的,注意维度的长度一定要和读入的数据匹配\n",
    "'''\n",
    "\n",
    "new_NC.createDimension('lat', len(lat[0]))\n",
    "new_NC.createDimension('lon', len(lon[0]))\n",
    "# new_NC.createDimension('Observed_ST', len(y_test_with_nan))\n",
    "# new_NC.createDimension('Estimated_ST', len(testPred_with_nan))\n",
    "\n",
    "new_NC.createDimension('depth', 33)\n",
    "new_NC.createDimension('time', len(time))\n",
    "\n",
    "new_NC.createVariable('lat', 'f', (\"lat\"))\n",
    "new_NC.createVariable('lon', 'f', (\"lon\"))\n",
    "new_NC.createVariable('depth', 'f', (\"depth\"))\n",
    "new_NC.createVariable('Observed_ST', 'f',(\"time\",\"depth\",\"lat\",\"lon\"))\n",
    "new_NC.createVariable('Estimated_ST', 'f',(\"time\",\"depth\",\"lat\",\"lon\"))\n",
    "\n",
    "time_var = new_NC.createVariable('time', 'f4',(\"time\"))\n",
    "time_var.units = 'months since 2015-01-15'\n",
    "time_var.long_name = 'Months in Monthly Means'\n",
    "time_var.axis = 'T'\n",
    "\n",
    "#向变量中填充数据\n",
    "new_NC.variables['lat'][:] = lat[0]\n",
    "new_NC.variables['lon'][:] = lon[0]\n",
    "new_NC.variables['time'][:] = np.array(time)\n",
    "new_NC.variables['depth'][:] = depth\n",
    "\n",
    "new_NC.variables['Observed_ST'][:]=np.array(y_test_with_nan)\n",
    "new_NC.variables['Estimated_ST'][:]=np.array(testPred_with_nan)\n",
    "\n",
    "\n",
    "#最后记得关闭文件\n",
    "new_NC.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f796bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:14:19.707360Z",
     "start_time": "2024-06-10T10:14:19.707360Z"
    }
   },
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379295b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python] *",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
